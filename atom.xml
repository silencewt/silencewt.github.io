<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Silence 婷婷 Blog]]></title>
  <subtitle><![CDATA[既然选择远方，便风雨兼程]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://silencewt.github.io/"/>
  <updated>2014-12-30T06:49:56.094Z</updated>
  <id>http://silencewt.github.io/</id>
  
  <author>
    <name><![CDATA[Wangt]]></name>
    <email><![CDATA[wangt_hust@163.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[图像融合文章系列汇总]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%E6%96%87%E7%AB%A0%E7%B3%BB%E5%88%97%E6%B1%87%E6%80%BB/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合文章系列汇总/</id>
    <published>2014-12-30T06:41:27.000Z</published>
    <updated>2014-12-30T06:47:46.000Z</updated>
    <content type="html"><![CDATA[<p>　　这是实验室项目的资料汇总，一方面便于自己整理，理清思路，另一方面让大家对图像融合有个大概的了解。以后项目还没有完结，以后还会有所补充。</p>
<p>图像融合文章系列汇总：</p>
<p><a href="http://silencewt.github.io/2014/12/29/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%80%EF%BC%89-%E6%A6%82%E8%BF%B0/" target="_blank" rel="external">图像融合（一）— 概述</a></p>
<p><a href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%80%EF%BC%89-%E7%AE%80%E5%8D%95%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88/" target="_blank" rel="external">图像融合（二）— 简单加权融合</a></p>
<p><a href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%89%EF%BC%89-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94/" target="_blank" rel="external">图像融合（三）— 拉普拉斯金字塔</a></p>
<p><a href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89-%E5%AF%B9%E6%AF%94%E5%BA%A6%E9%87%91%E5%AD%97%E5%A1%94/" target="_blank" rel="external">图像融合（四）— 对比度金字塔</a></p>
<p><a href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%BA%94%EF%BC%89-%E6%A2%AF%E5%BA%A6%E9%87%91%E5%AD%97%E5%A1%94/" target="_blank" rel="external">图像融合（五）— 梯度金字塔</a></p>
<p><a href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E5%85%AD%EF%BC%89-%E5%B0%8F%E6%B3%A2%E8%9E%8D%E5%90%88/" target="_blank" rel="external">图像融合（六）— 小波融合</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　这是实验室项目的资料汇总，一方面便于自己整理，理清思路，另一方面让大家对图像融合有个大概的了解。以后项目还没有完结，以后还会有所补充。</p>
<p>图像融合文章系列汇总：</p>
<p><a href="http://silencewt.github.io/2014/]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（六）-- 小波融合]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E5%85%AD%EF%BC%89-%E5%B0%8F%E6%B3%A2%E8%9E%8D%E5%90%88/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合（六）-小波融合/</id>
    <published>2014-12-30T05:47:21.000Z</published>
    <updated>2014-12-30T06:35:32.000Z</updated>
    <content type="html"><![CDATA[<h3 id="基于小波的融合（wavelet）">基于小波的融合（wavelet）</h3>
<p>　　小波变换的固有特性使其在图像处理中有如下优点：完善的重构能力，保证信号在分解过程中没有信息损失和冗余信息；把图像分解成平均图像和细节图像的组合，分别代表了图像的不同结构，因此容易提取原始图像的结构信息和细节信息；小波分析提供了与人类视觉系统方向相吻合的选择性图像。</p>
<p>　　离散小波变换(Discrete Wavelet Transform, DWT)。DWT的函数基由一个称为母小波或分析小波的单一函数通过膨胀和平移获得。因而，DWT同时具有时域和频域分析能力，与一般的金字塔分解相比，DWT图像分解具有以下优势：</p>
<ol>
<li>具有方向性，在提取图像低频信息的同时，还可获得了水平、垂直和对角三个方向的高频信息；</li>
<li>通过合理的选择母小波，可使DWT在压缩噪声的同时更有效的提取纹理、边缘等显著信息；</li>
<li>金字塔分解各尺度之间具有信息的相关性，而DWT在不同尺度上具有更高的独立性。</li>
</ol>
<p>DWT融合算法基本思想与金字塔算法一致，即：首先对源图像进行小波变换，然后按照一定规则对变换系数进行合并；最后对合并后的系数进行小波逆变换得到融合图像。由于不具有移不变性，基于DWT的标准小波融合算法获取的融合图像通常会存在“振铃”干扰;特别在处理连续的图像序列时，融合结果会出现明显的闪烁和抖动现象。</p>
<h4 id="1、原理阐述">1、原理阐述</h4>
<p>　　（1）小波的简单计算原理</p>
<p>　　 [x0，x1，x2，x3]=[90，70，100，70] 为达到压缩 我们可取 (x0+x1)/2  (x0-x1)/2 来代表 x0,x1  这样 [90,70] 可表示为 [80,10] 80即平均数 10是小范围波动数（可想象出一种波的形状） [90,70] —〉[80,10] , [100,70] —〉 [85,15] 可以想象80 和85 都是局部的平均值反映大的总体的状态，是变化相对缓慢的值，可以认为他们是低频部分的值。 而10、15是小范围波动的值局部变换较快，可以认为他们是高频部分的值。</p>
<p>　　1、 FIRST：把[90,70,100,70] 写成 [80,85,10,15] 即把低频部分写在一起（记频率L） 高频部分写在一起（H) </p>
<p>　　2、 SECOND：而[80,85] 又可经同样的变换—&gt; [82.5, -2.5] 这样 82.5表示更低频的信息(记频率LL) -2.5则表示了频率L上的波动 </p>
<p>　　3、最后[90,70,100,70] —〉[82.5, -2.5, 10, 15] 这样信息就可被压缩了（数字范围小了）</p>
<p>　　现在再来扩展一下  [90,70]—-&gt; [80,10] 写成矩阵 [90,70] * [1/2, 1/2]<br>[1/2 ,-1/2] 矩阵[1,1；1,-1]/2为haar转换矩阵。</p>
<p>　　如果是[90,70,100,70]第一步就可以写成矩阵M1：[0.5,0,0.5,0; 0.5,0,-0.5,0; 0,0.5,0,0.5;0,0.5,0,-0.5]，第二步只对低频L操作，高频不变可写成M2：[1/2,  1/2, 0, 0; 1/2, -1/2, 0, 0; 0,  0,  1, 0 ;0,  0,  0, 1]。另M= M1<em>M2，可得到4</em>4的点阵操作。</p>
<p>　　第一步运算后原图像缩小至左边一半了，右边的是对应波动信息；</p>
<p>　　第二步运算后图像又缩小至左边一半了，对应波动信息。</p>
<p>　　对一幅图像先进行行变化，在进行列变化，那么就是小波变化了。</p>
<p><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.1.png" alt="wave1"></p>
<p>　　LL：水平低频，垂直低频</p>
<p>　　LH：水平低频，垂直高频</p>
<p>　　HL：水平高频，垂直低频</p>
<p>　　HH：水平高频，垂直高频</p>
<p>　　其中，L表示低频，H表示高频，下标1、2表示一级或二级分解。在每一分解层上，图像均被分解为LL，LH，HH和HL四个频带，下一层的分解仅对低频分量LL进行分解。这四个子图像中的每一个都是由原图与一个小波基函数的内积后，再经过在x和y方向都进行2倍的间隔采样而生成的。这是正变换，也就是图像的分解；逆变换，也就是图像的重建。是通过图像的增频采样和卷积来实现的。这里有个问题进过处理后，数据或超出255或者出现负数，需要将其归一化到0-255之间，方可显示图像。这里介绍的只是简单的小波计算，小波计算的而不同就在于选取不同的小波系数，一般有haar小波，sym2小波等。</p>
<p>资料：<a href="http://www.blogbus.com/shijuanfeng-logs/221385402.html" target="_blank" rel="external">http://www.blogbus.com/shijuanfeng-logs/221385402.html</a></p>
<h4 id="2、融合规则">2、融合规则</h4>
<p><strong>规则一</strong>：系数绝对值较大法</p>
<p>　　该融合规则适合高频成分比较丰富，亮度、对比度比较高的源图像，否则在融合图像中只保留一幅源图像的特征，其他的特征被覆盖。小波变换的实际作用是对信号解相关，并将信号的全部信息集中到一部分具有大幅值的小波系数中。这些大的小波系数含有的能量远比小系数含有的能量大，从而在信号的重构中，大的系数比小的系数更重要。</p>
<p><strong>规则二</strong>：加权平均法</p>
<p>　　权重系数可调，适用范围广，可消除部分噪声，源图像信息损失较少，但会造成图像对比度的下降，需要增强图像灰度。</p>
<p><strong>规则三</strong>：局部方差准则</p>
<p>　　设A(x,y)和B(x,y)分别为高频子图像数据值，F(x,y)为相应高频子图像融合值，将A(x,y)和B(x,y)分成若干个M×N子块图像。对每个子块图像进行数值分布统计，计算其方差。确定A和B图像每个子块图像加权系数K1和K2。如果A图像子块方差大于B图像子块方差,则K1≥K2，否则K1&lt;K2。确定每个子块图像的数据融合数值为：F(i,j)=K1A(i,j)+K2B(i,j)。</p>
<h4 id="3、融合应用">3、融合应用</h4>
<p>　　若对二维图像进行N层的小波分解,最终将有(3N+1)个高低频带，其中包含3N个高频带和一个低频带。图像融合的基本步骤如下。</p>
<p>　　1）对每一源图像分别进行小波分解，建立图像的小波金字塔分解。</p>
<p>　　2）对各分解层分别进行融合处理，采用不同的融合算子对各分解层的不同频率分量进行融合处理，最终得到融合后的小波金字塔。低频：加权平均，高频：绝对值取大。</p>
<p>　　3）对融合后所得的小波金字塔进行小波逆变换，所得到的重构图像即为融合后的图像。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.2.png" alt="wave2"></p>
<p>　　图像的低频部表现的是图像的概貌和平均特性；图像的高频反应的是图像的细节特性，如图像的边缘、区域边界等。</p>
<p>　　融合规则：</p>
<p>　　基于局部方差的融合规则：在邻域W中，图像I在以（i ，j)为中心点的局部方差定义：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.3.png" alt="wave3"></p>
<p>　　式中为图像I 的均值，M，N 分别为局部区域的行数和列数，这里取局部区域为3*3，基于局部方差的融合方式常用的方法是选择法，即通常说的局部方差取大法。方差选择法的融合规则<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.4.png" alt="wave4"></p>
<p>　　L为分解尺度， 表示图像小波系数，<img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.5.png" alt="wave5"> 表示图像小波系数， =d=H,V,D分别表示的是水平、垂直、对角高频分量。如果两幅图片直接使用局部方差法进行融合，局部方差相差较大时，采用局部方差取大法能够比较完整的存储图像的微小细节。一旦局部方差相差很小时，局部方差取大法会使图像细节失真。</p>
<p>　　图像融合有一个重要的目的，即将图像的边缘、细节等都包含到融合图像中。一种方法是将图像的边缘提取出来，将它应用到相应的融合算法中。图像边缘检测的最好的算子是 canny 算子，将canny算子和局部方差的融合规则的算法相结合，提出了一种新的改进融合方法。融合步骤如下：</p>
<p>　　（1）小波分解。对于图像 A，B 分别进行 3 层小波分解，得到低频分量AA、AB和高频分量DLH，DLV，DLD。</p>
<p>　　（2）低频融合。对低频分量AA 和AB 所有的像素点计算其局部方差Var(i ,j)AA和 Var(i ,j)BA，然后进行归一化：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.6.png" alt="wave6"></p>
<p>　　然后，利用归一化的局部方差，按照如下：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.7.png" alt="wave7"></p>
<p>　　（3）高频融合。在图像 A 和 B 的每一个高频分DLA，DLB中，对每一个高频分量用 canny 算子进行边缘提取，再对边缘图像的每一个元素计算局部方差：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.8.png" alt="wave8"></p>
<p>　　其中 <img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.9.png" alt="wave9"><br>表示源图像的第l层经 canny 算子处理的高频系数 <img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.10.png" alt="wave10">为源图像的第l层经 canny 算子提取后的均值。<img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.11.png" alt="wave11"> 是对源图像的第l层高频分量进行边缘提取后求得的局部方差。<br> <img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-wave1.12.png" alt="wave12"></p>
<p>　　（4）小波重构。对融合后的系数进行小波重构，得到融合后的图像。</p>
<p>　　附：这里介绍的小波是最简单的形式，融合规则也比较常用，很多红外和可见的融合也都用到了这里的规则，所以，实现这里面的算法来适用我们的应用。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="基于小波的融合（wavelet）">基于小波的融合（wavelet）</h3>
<p>　　小波变换的固有特性使其在图像处理中有如下优点：完善的重构能力，保证信号在分解过程中没有信息损失和冗余信息；把图像分解成平均图像和细节图像的组合，分别代表了图像的不同结构，因此]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（五）-- 梯度金字塔]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%BA%94%EF%BC%89-%E6%A2%AF%E5%BA%A6%E9%87%91%E5%AD%97%E5%A1%94/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合（五）-梯度金字塔/</id>
    <published>2014-12-30T05:14:35.000Z</published>
    <updated>2014-12-30T05:34:53.000Z</updated>
    <content type="html"><![CDATA[<p>　　基于梯度金字塔(Gradient Pyramid,GP)分解的图像融合算法。GP 也是一种基于高斯金字塔的多尺度分解算法。通过对高斯金字塔每层图像进行梯度算子运算，便可获得图像的 GP表示。GP 每层分解图像都包含水平、垂直和两个对角线四个方向的细节信息，能更好地提取出图像的边缘信息，提高了稳定性和抗噪性。具有方向性的梯度塔形分解能够很好地提供图像的方向边缘和细节信息。</p>
<p>1、<strong>原理阐述</strong><br>（1）得到高斯金字塔（如上）</p>
<p>（2）对图像高斯金字塔的各分解层（最高层除外）分别进行梯度方向滤波，便可得到梯度塔形分解：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.1.png" alt="Gradius1"></p>
<p>　　这里•为卷积运算，DL K表示第L层第k方向梯度塔形图像，GL 为图像的高斯金字塔的第L层图像，dK表示第k方向梯度滤波算子，定义为：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.2.png" alt="gradius2"></p>
<p><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.3.png" alt="gradius3"></p>
<p>　　经过 d1、d2、d3、d4对高斯金字塔各层进行方向梯度滤波，在每一分解层上（最高层除外）均可得到包含水平、垂直以及两个对角线方向细节信息的4个分解图像。可见图像的梯度塔形分解不仅是多尺度、多分辨率分解，而且每一分解层（最高层除外）又由分别包含 4个方向细节信息的图像组成。</p>
<p>　　这里跟上面不同的就是每一层是独立的，不需要涉及到上一层的上采样结果。对应层的Gl与3*3的核做卷积，在加上Gl的值之后取相应方向的值，就可以生成对应方向的系数了。</p>
<p>   （3）重构</p>
<p>　　对金字塔图像每一层各方向分别融合后，就需要由梯度金字塔重构原图像，须引入FSD 拉普拉斯金字塔作为中间结果，即将梯度金字塔转换为拉普拉斯金字塔，再由拉普拉斯金字塔重构原图像，其构建过程如下：</p>
<p>　　1、将方向梯度金字塔转换为方向拉普拉斯金字塔（FSD型）filter-subtract-decimate。设 FSD型金字塔的第L层图像为LL，<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.4.png" alt="gradius4"></p>
<p>　　2、将FSD 拉普拉斯金字塔图像变换为拉普拉斯金字塔图像。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.5.png" alt="gradiu5"></p>
<p>　　注意I不是单位矩阵，只是中间一个元素为1。（不懂）</p>
<p>　　3、由拉普拉斯金字塔重构原图像将GL内插值进行放大，使放大后的图像尺寸与GL - 1的尺寸相同。这里就和前面的一样（pyrup）。</p>
<p>2、融合应用</p>
<p>　　采用基于区域的融合规则，基于区域的融合方法的基本思想是：在对某一分解层图像进行融合处理时，为了确定融合后图像的像素，不仅要考虑参加融合的源图像中对应的各像素，而且要考虑参加融合的像素的局部领域。即比较源图像的某方面特征，从而动态地选这方面特征突出的源图像组成融合结果。</p>
<p>　　梯度是一个矢量，指向边缘法线方向上取得局部的最大值的方向，和图像的边缘方向总 是正交（垂直）的。所以基于梯度的滤波器，又称边缘算子。图像经梯度滤波器滤波后，突出了相邻点间灰度级的变化，达到增强边缘的目的。以区域各点灰度值之和为特征量，进行源图像分解层的融合时，来自哪个区域的特征的值大，就将该区域中心像素点的灰度值作为融合后图像分解层上该位置的像素灰度值。这样就能很好的提取图像的边缘信息。<br>　　<img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-gp1.6.png" alt="gradius6"></p>
<p>2、<strong>融合的基本步骤</strong></p>
<p>2.1、对每一源图像分别进行梯度塔形分建立图像的梯度金字塔。</p>
<p>2.2、对图像梯度金字塔的各分解层分别进行融合处理；不同的分解层、不同方向细节图像采用不同的融合算子进行融合处理，最终得到融合后图像的梯度金字塔。</p>
<p>2.3、对融合后所得梯度金字塔进行逆塔形变换（即进行图像重构），所得到的重构图像即融合图像对于融合规则可以选用基于区域信息的，也可以简单的取最大值的方法。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　基于梯度金字塔(Gradient Pyramid,GP)分解的图像融合算法。GP 也是一种基于高斯金字塔的多尺度分解算法。通过对高斯金字塔每层图像进行梯度算子运算，便可获得图像的 GP表示。GP 每层分解图像都包含水平、垂直和两个对角线四个方向的细节信息，能更好地提取出]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（四）-- 对比度金字塔]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89-%E5%AF%B9%E6%AF%94%E5%BA%A6%E9%87%91%E5%AD%97%E5%A1%94/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合（四）-对比度金字塔/</id>
    <published>2014-12-30T04:59:55.000Z</published>
    <updated>2014-12-30T05:10:09.000Z</updated>
    <content type="html"><![CDATA[<h3 id="对比度金字塔融合">对比度金字塔融合</h3>
<p>　　在考虑人类视觉系统对局部对比度敏感这一视觉特性的基础上，提出了基于对比度金字塔(Contrast Pyramid，CP)分解的图像融合算法。CP 分解类似于 LP 分解，但它的每一层图像是高斯金字塔相邻两层图像的比率。 CP 融合算法应用于合成孔径雷达和前视红外图像融合。</p>
<h4 id="1、原理阐述">1、原理阐述</h4>
<p>　　<strong>（1）得到高斯金字塔（如上篇）</strong></p>
<p>　　<strong>（2）对比度金字塔</strong></p>
<p>　　用高斯金字塔得到上采样并高斯卷积之后的预测图像<em>Gl，</em>Gl的尺寸和Cl-1相同，即经过放大算子的处理（pyrup）。图像的对比度通常定义为：C = (g -gb)/gb= g/gb-I，这里g为图象某位置处的灰度值、gb为该位置处的背景灰度值、I表示单位灰度值图像。因窗口函数w(m，n)具低通滤波特性，所以G*l+1可以看作是Gl的背景，故可定义图像的对比度金字塔为：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-cp1.1.jpg" alt="contrast1"></p>
<p>　　就是0层的G0除以G1上采样的得到的*G1再减去1，得到的就是对比度金字塔。</p>
<p>　　<strong>（3）重构</strong><br>　　<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-cp1.2.png" alt="contrast2"></p>
<p>　　从对比度金字塔(CN、CN-1、、、C0)的顶层CN开始、依次令l = N、N-1、、、0逐层由上到下、可依次得到高斯金字塔的各层GN、GN-1、G0。最终精确重构原始图像（高斯金字塔的最底层G0即为原始图象）。</p>
<h4 id="2、融合应用">2、融合应用</h4>
<p>　　这里的应用和上面不同的就是融合规则的不同。</p>
<p>　　设A、B为两幅原始图像，F为融合后的图像。其融合的基本步骤如下：</p>
<p>　　1）对每一源图像分别进行对比度塔形分解，建立各图像的对比度金字塔；</p>
<p>　　2）对图像金字塔的各分解层分别进行融合处理，不同的分解层采用不同的融合算子进行融合处理，最终得到融合后图像的对比度金字塔；</p>
<p>　　3）对融合后所得对比度金字塔进行逆塔形变换（图像重构），所得到的重构图像即为融合图像。</p>
<p>　　其中<strong>一种融合规则</strong>为：采用像素取大的原则。因为对比度大的像素是图像中相对突出和比较重要的像素。即获得两个图像的对比度金字塔后，差值越大就代表处变化越大，存在明显的信息，那么对应的就取该处变化大的值，保留重要的变化信息。</p>
<p>　　<strong>另一种融合规则</strong>：基于区域特性量测的加权平均融合算子，该融合规则及融合算子的确定方法如下：</p>
<p>　　分别计算两幅图像相应分解层上对应局部区域的能量：ElA及ElB：<br>　　<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-cp1.3.png" alt="contrast3"></p>
<p>　　式中El(n,m)表示对比度金字塔第l层上，以(n,m)为中心位置的局部区域能量；Ll表示对比度金字塔的第l层图像；wl(n’ ,m’ )为与Ll对应的权系数；j、k定义了局部区域的大小(例如3<em>3、5</em>5或7*7等)；n’、m’的变化范围在j、k内。这里不知道w是怎么取值的。</p>
<p>　　这个算法有点麻烦，具体的见：<br>　　<a href="http://www.docin.com/p735309332.html" target="_blank" rel="external">http://www.docin.com/p735309332.html</a></p>
<hr>
<p><strong>基于对比度塔形分解的图像融合方法的物理意义在于</strong>：</p>
<p>1）对比度塔形分解将原始图像分别分解到具有不同分辨率、不同空间频率的一系列分解层上（从底层到顶层，空间频率依次降低），同时，每一分解层均反映了相应空间频率上图像的对比度信息。</p>
<p>2）融合过程是在各空间频率层上分别进行的，这样就可能针对不同分解层的不同频带上的特征与细节，采用不同的融合算子，以达到突出特定频带上特征与细节的目的。基于对比度塔形分解的图像融合恰恰是在不同的空间频带上进行融合处理的，因而可能获得与人的视觉特性更为接近的融合效果。</p>
<p>​</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="对比度金字塔融合">对比度金字塔融合</h3>
<p>　　在考虑人类视觉系统对局部对比度敏感这一视觉特性的基础上，提出了基于对比度金字塔(Contrast Pyramid，CP)分解的图像融合算法。CP 分解类似于 LP 分解，但它的每一层图像是高斯金字塔相邻两层]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（三）-- 拉普拉斯金字塔]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%89%EF%BC%89-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合（三）-拉普拉斯金字塔/</id>
    <published>2014-12-30T03:23:08.000Z</published>
    <updated>2014-12-30T04:56:53.000Z</updated>
    <content type="html"><![CDATA[<h3 id="2、拉普拉斯金字塔融合">2、拉普拉斯金字塔融合</h3>
<p>　　图像金字塔方法的原理是：将参加融合的的每幅图像分解为多尺度的金字塔图像序列，将低分辨率的图像在上层，高分辨率的图像在下层，上层图像的大小为前一层图像大小的1/4。层数为0,1,2……N。将所有图像的金字塔在相应层上以一定的规则融合，就可得到合成金字塔，再将该合成金字塔按照金字塔生成的逆过程进行重构，得到融合金字塔。这个总的思路就是一下所有基于金字塔融合的算法过程，不同点就在于分解构造的金字塔不同，每层的融合规则不一样，重构的方法不同而已。金字塔方法最先实现了这种思想，之后小波方法进一步完善和发展了这种多尺度融和的思想。</p>
<h4 id="2-1、原理阐述">2.1、原理阐述</h4>
<h5 id="（1）高斯金字塔"><strong>（1）高斯金字塔</strong></h5>
<p>　　高斯金字塔是最基本的图像塔。首先将原图像作为最底层图像G0（高斯金字塔的第0层），利用高斯核（5*5）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。</p>
<p>高斯金字塔的构建过程为：假设高斯金字塔的第L层图像为Gl：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.1.jpg" alt="Laplacian1"></p>
<p>式中N为高斯金字塔顶层层号，Rl和Cl分别为高斯金字塔第l层的行数和列数W（m，n）是一个二维可分离的5*5窗口函数，表达式为：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.2.jpg" alt="Laplace2"></p>
<p>　　由G0，G1，，，GN，就构成了一个高斯金字塔，其中G0为高斯金字塔的底层（与原图像相同）GN为金字塔的顶层。由此可见高斯金字塔的当前层图像就是对其前一层图像首先进行高斯低通滤波，然后再进行隔行和隔列的降2采样而生成的。前一层图像大小依次为当前层图像大小的4倍。</p>
<p>　　Opencv中使用pyrdown函数就可以获得高斯金字塔。</p>
<h5 id="（2）拉普拉斯金字塔"><strong>（2）拉普拉斯金字塔</strong></h5>
<p>　　在高斯金字塔的运算过程中，图像经过卷积和下采样操作会丢失部分高频细节信息。为描述这些高频信息，人们定义了拉普拉斯金字塔(Laplacian Pyramid， LP)。用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像即为 LP 分解图像。</p>
<p>　　将Gl内插方法得到放大图像<em>Gl，使</em>Gl的尺寸与*Gl-1的尺寸相同，即放大算子Expand<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.3.jpg" alt="Laplace3"></p>
<p>　　该式子实现两个步骤：在偶数行和列插入0，然后使用下采样中的高斯核进行滤波处理，得到和l-1层一样大小的图像。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.4.jpg" alt="Laplace4"></p>
<p>　　N为拉普拉斯金字塔顶层的层号LPl是拉普拉斯金字塔分解的第L层图像。由LP0，LP1、LP2…LPN构成的金字塔即为拉普拉斯金字塔。它的每一层L0图像是高斯金字塔本层G0图像与其高一层图像G1经内插放大后图像*G1的差，此过程相当于带通滤波，因此拉普拉斯金字塔又称为带通金字塔分解。</p>
<p>　　内插方法：opencv中有实现的函数pyrup。可以得到*G1。然后在两个函数作差，相减就可以得到拉普拉斯金字塔。</p>
<p>　　求得每个图像的拉普拉斯金字塔后需要对相应层次的图像进行融合，具体的融合规则有，取大、取小，等等。</p>
<h5 id="（3）重构"><strong>（3）重构</strong></h5>
<p>　　对融合后的拉普拉斯金字塔，从其顶层开始逐层从上至下按下式进行递推，可以恢复其对应的高斯金字塔，并最终可得到原图像G0。就是从最高层开始使用内插的方法。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.5.jpg" alt="Laplace5"></p>
<h4 id="2-2、融合应用">2.2、融合应用</h4>
<p>　　图像拉普拉斯金字塔分解的目的是将源图像分别分解到不同的空间频带上，融合过程是在各空间频率层上分别进行的，这样就可以针对不同分解层的不同频带上的特征与细节，采用不同的融合算子以达到突出特定频带上特征与细节的目的。即有可能将来自不同图像的特征与细节融合在一起。</p>
<h5 id="（1）顶层处理"><strong>（1）顶层处理</strong></h5>
<p>　　设LAl和LBl分别为源图像A,B经过拉普拉斯金字塔分解后得到的第l层图像，融合后的结果为LFl。当l=N时，LAN和LBN分别为源图像A，B经过拉普拉斯金字塔分解后得到的顶层图像。对于顶层图像的融合，首先计算以其各个像素为中心的区域大小为M*N(M、N取奇数且M &gt;= 3、N &gt;= 3)的区域平均梯度：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.6.jpg" alt="Laplace6"></p>
<p>其中，Ix与Iy分别为像素f(x,y)在x与y方向上的一阶差分，定义如下：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.7.jpg" alt="Laplace7"></p>
<p>　　因此对于顶层图像中的每一个像素LAN(i, j)和LBN(i, j)都可以得到与之相对应的区域平均梯度GA(i, j)和GB(i, j)。由于平均梯度反映了图像中的微小细节反差和纹理变化特征，同时也反映出图像的清晰度。一般来说平均梯度越大，图像层次也丰富，则图像越清晰。因此顶层图像的融合结果为：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.8.jpg" alt="Laplace8"></p>
<h5 id="（2）各层次处理"><strong>（2）各层次处理</strong></h5>
<p>　　当0小于i小于N时，则对于经过拉普拉斯金字塔分解的第l层图像，首先计算其区域能量：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.9.jpg" alt="Laplace9"></p>
<p>则其他层次图像的融合结果为：</p>
<p><img src="http://7te8s4.com1.z0.glb.clouddn.com/merge-lp1.10.jpg" alt="Laplace410"></p>
<p>在得到金字塔各个层次的融合图像LF1、LF2、LFN后。通过前面的重构，便可得到最终的融合图像。</p>
<p>　　第二种融合规则：</p>
<p>　　采用最高层系数取平均，其余各层系数绝对值取大的融合策略进行融合。融合后图像的系数（灰度值）越接近较清晰图像的灰度值就说明融合效果好。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="2、拉普拉斯金字塔融合">2、拉普拉斯金字塔融合</h3>
<p>　　图像金字塔方法的原理是：将参加融合的的每幅图像分解为多尺度的金字塔图像序列，将低分辨率的图像在上层，高分辨率的图像在下层，上层图像的大小为前一层图像大小的1/4。层数为0,1,2……N。将所有图]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（二）-- 简单加权融合]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%80%EF%BC%89-%E7%AE%80%E5%8D%95%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88/"/>
    <id>http://silencewt.github.io/2014/12/30/图像融合（一）-简单加权融合/</id>
    <published>2014-12-30T03:06:13.000Z</published>
    <updated>2014-12-30T03:09:43.000Z</updated>
    <content type="html"><![CDATA[<p>简单加权融合也叫做<strong>像素加权平均法</strong>（Weighted Averaging，WA）是最简单、直接的图像融合方法。它具有简单易实现、运算速度快的优点，并能提高融合图像的信噪比，但是这种方法削弱了图像中的细节信息，降低了图像的对比度，在一定程度上使得图像中的边缘变模糊，在多数应用场合难以取得满意的融合效果。</p>
<p>　　优化：<strong>主成分分析</strong>(Principal Component Analysis，PCA)就是一种常用的系数优化方法，利用主成分分析确定的权值可以得到一幅亮度方差最大的融合图像。PCA方法运用于高分辨率全色图像与低分辨率多光谱图像的融合时，通过用高分辨率全色图像替代由低分辨率多光谱图像提取出的第一主成分，得到同时具有高空间分辨率和高光谱分。</p>
<p>　　从性能上讲，主成分分析法更像是对源图像的选择而不是对源图像中显著信息的融和。局限性：以全局方差作为信息显著性度量通常会把较大的权值分配给方差较大的源图像。实际应用中，当某一传感器输出图像对比度较低时，这种权值分配方法效果会比较好，但就一般情况而言，这种分配方法并不科学。此外，主成分分析法对图像中的死点、噪声等干扰信息非常敏感，这些干扰信息会显著的提高图像的全局方差。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>简单加权融合也叫做<strong>像素加权平均法</strong>（Weighted Averaging，WA）是最简单、直接的图像融合方法。它具有简单易实现、运算速度快的优点，并能提高融合图像的信噪比，但是这种方法削弱了图像中的细节信息，降低了图像的对比度，在一定程度上使]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR系统系列文章汇总]]></title>
    <link href="http://silencewt.github.io/2014/12/30/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%E7%B3%BB%E7%BB%9F%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E6%B1%87%E6%80%BB/"/>
    <id>http://silencewt.github.io/2014/12/30/车牌识别LPR系统系列文章汇总/</id>
    <published>2014-12-30T02:50:35.000Z</published>
    <updated>2014-12-30T02:51:19.000Z</updated>
    <content type="html"><![CDATA[<p>　　这里的LPR的的几篇文章是之前项目的一些相关资料的整理，涉及实验室内部的资料就没有放上来，希望能对想了解这方面的同学，有所帮助，那怕了解个大概也好。知道整体的思路就好。当初就是一个人瞎摸索，走了很多的弯路，也算给其他人一点建议吧。</p>
<p>车牌识别LPR系统系列文章汇总：</p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%80%EF%BC%89-%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF/" target="_blank" rel="external">车牌识别LPR（一）— 研究背景</a></p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%BA%8C%EF%BC%89-%E8%BD%A6%E7%89%8C%E7%89%B9%E5%BE%81%E5%8F%8A%E9%9A%BE%E7%82%B9/" target="_blank" rel="external">车牌识别LPR（二）— 车牌特征及难点</a></p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%89%EF%BC%89-LPR%E7%B3%BB%E7%BB%9F%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/" target="_blank" rel="external">车牌识别LPR（三）— LPR系统整体结构</a></p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%9B%9B%EF%BC%89-%E8%BD%A6%E7%89%8C%E5%AE%9A%E4%BD%8D/" target="_blank" rel="external">车牌识别LPR（四）— 车牌定位</a> </p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%BA%94%EF%BC%89-%E4%B8%80%E7%A7%8D%E8%BD%A6%E7%89%8C%E5%AE%9A%E4%BD%8D%E6%B3%95/" target="_blank" rel="external">车牌识别LPR（五）— 一种车牌定位法</a> </p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%85%AD%EF%BC%89-%E5%AD%97%E7%AC%A6%E5%88%86%E5%89%B2/" target="_blank" rel="external">车牌识别LPR（六）— 字符分割</a></p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%83%EF%BC%89-%E5%AD%97%E7%AC%A6%E7%89%B9%E5%BE%81/" target="_blank" rel="external">车牌识别LPR（七）— 字符特征</a></p>
<p><a href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%85%AB%EF%BC%89-%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/" target="_blank" rel="external">车牌识别LPR（八）— 字符识别</a> </p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　这里的LPR的的几篇文章是之前项目的一些相关资料的整理，涉及实验室内部的资料就没有放上来，希望能对想了解这方面的同学，有所帮助，那怕了解个大概也好。知道整体的思路就好。当初就是一个人瞎摸索，走了很多的弯路，也算给其他人一点建议吧。</p>
<p>车牌识别LPR系统系列文]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图像融合（一）-- 概述]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88%EF%BC%88%E4%B8%80%EF%BC%89-%E6%A6%82%E8%BF%B0/"/>
    <id>http://silencewt.github.io/2014/12/29/图像融合（一）-概述/</id>
    <published>2014-12-29T12:28:00.000Z</published>
    <updated>2014-12-29T12:33:59.000Z</updated>
    <content type="html"><![CDATA[<p>　　这是2014年第二部分的内容。关于三光检测融合的一些资料整理，部分内容由于保密原因没有写出来，这里整理的内容都是网上或者文章里可以看到的。</p>
<h3 id="一、概述">一、概述</h3>
<p>　　图像融合是图像处理中重要部分，能够协同利用同一场景的多种传感器图像信息，输出一幅更适合于人类视觉感知或计算机进一步处理与分析的融合图像。它可明显的改善单一传感器的不足，提高结果图像的清晰度及信息包含量，有利于更为准确、更为可靠、更为全面地获取目标或场景的信息。</p>
<p>　　图像融合主要应用于军事国防上、遥感方面、医学图像处理、机器人、安全和监控、生物监测等领域。用于较多也较成熟的是红外和可见光的融合，在一副图像上显示多种信息，突出目标。</p>
<p>　　融合过程可以在不同的层次上进行，可分为：信号级、像素级、特征级，决策级。</p>
<h4 id="1-1、信号级">1.1、信号级</h4>
<p>　　在最低层对未经处理的传感器输出在信号域进行混合，产生一个融合后的信号。融合后的信号与源信号形式相同但品质更好，来自传感器的信号可建模为混有不同相关噪声的随机变量。此种情况下，融合可以考虑为一种估计过程，信号级图像融合在很大程度上是信号的最优集中或分布检测问题，对信号时间和空间上的配准要求最高。</p>
<h4 id="1-2、像素级">1.2、像素级</h4>
<p>　　像素级图像融合是三个层次中最基本的融合，经过像素级图像融合以后得到的图像具有更多的细节信息，如边缘、纹理的提取，有利于图像的进一步分析、处理与理解，还能够把潜在的目标暴露出来，利于判断识别潜在的目标像素点的操作，这种方法才可以尽可能多的保存源图像中的信息，使得融合后的图片不论是内容还是细节都有所增加，这个优点是独一无二的，仅存在于像素级融合中。但像素级图像融合的局限性也是不能忽视的，由于它是对像素点进行操作，所以计算机就要对大量的数据进行处理，处理时所消耗的时间会比较长，就不能够及时地将融合后图像显示出来，无法实现实时处理；另外在进行数据通信时，信息量较大，容易受到噪声的影响；还有如果没有将图片进行严格的配准就直接参加图像融合，会导致融合后的图像模糊，目标和细节不清楚、不精确。</p>
<h4 id="1-3、特征级">1.3、特征级</h4>
<p>　　特征级图像融合是从源图像中将特征信息提取出来，这些特征信息是观察者对源图像中目标或感兴趣的区域，如边缘、人物、建筑或车辆等信息，然后对这些特征信息进行分析、处理与整合从而得到融合后的图像特征。对融合后的特征进行目标识别的精确度明显的高于原始图像的精确度。特征级融合对图像信息进行了压缩，再用计算机分析与处理，所消耗的内存与时间与像素级相比都会减少，所需图像的实时性就会有所提高。特征级图像融合对图像匹配的精确度的要求没有第一层那么高，计算速度也比第一层快，可是它提取图像特征作为融合信息，所以会丢掉很多的细节性特征。</p>
<h4 id="1-4、决策级">1.4、决策级</h4>
<p>　　决策级图像融合是以认知为基础的方法，它不仅是最高层次的图像融合方法，抽象等级也是最高的。决策级图像融合是有针对性的，根据所提问题的具体要求，将来自特征级图像所得到的特征信息加以利用，然后根据一定的准则以及每个决策的可信度（目标存在的概率）直接作出最优决策。三个融合层级中，决策级图像融合的计算量是最小的，可是这种方法对前一个层级有很强的依赖性，得到的图像与前两种融合方法相比不是很清晰。将决策级图像融合实现起来比较困难，但图像传输时噪声对它的影响最小。</p>
<p>　　综合以上，<strong>研究和应用最多的是像数级图像融合</strong>，目前提出的绝大多数的图像融合算法均属于该层次上的融合。图像融合狭义上指的就是像数级图像融合。本文研究的也正是像素级图像融合算法。</p>
<p>　　<strong>红外和可见的融合很多文献都是从像素级入手，基于已有的融合算法，根据实际情况，来设立融合规则，得到适合实际应用场景的融合图像。</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　这是2014年第二部分的内容。关于三光检测融合的一些资料整理，部分内容由于保密原因没有写出来，这里整理的内容都是网上或者文章里可以看到的。</p>
<h3 id="一、概述">一、概述</h3>
<p>　　图像融合是图像处理中重要部分，能够协同利用同一场景的多种传感器图]]>
    </summary>
    
      <category term="图像融合" scheme="http://silencewt.github.io/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（八）-- 字符识别]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%85%AB%EF%BC%89-%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（八）-字符识别/</id>
    <published>2014-12-29T08:35:10.000Z</published>
    <updated>2014-12-29T08:43:04.000Z</updated>
    <content type="html"><![CDATA[<p>​第八篇：字符识别</p>
<p>　　车牌定位、车牌倾斜校正、车牌字符分割都是为车牌字符识别做的前提工作，这些前提工作直接关系到车牌识别系统的性能。车牌字符识别是车牌识别系统的核心部分，车牌字符识别的准确率是衡量车牌识别系统的一个很重要的指标。</p>
<p>　　一般字符识别的方法就是采用模式识别方法，简单的来说模式识别就是先通过提取输入模板的特征，然后通过模板的特征对样本进行分类，从而识别出样本。模式识别主要包括：数据采集、预处理、特征提取、特征匹配，其结构框架如图：</p>
<p>　　字符识别是模式识别的一个重要应用，首先提取待识别字符的特征；然后对提取出来的特征跟字符模板的特征匹配；最后根据准则判定该字符所属的类别。不同的训练方法，不同的特征提取， 不同的匹配规则，就相应的有不同的字符识别方法，基本上很多就是在这些地方做改进，或者是采用新的规则。但是万变不离其宗。</p>
<p><strong>（1）模板匹配字符识别算法</strong></p>
<p>　　模板匹配字符识别算法是图像识别中的经典算法之一，该算法的核心思想是：通过比较待识别字符图像的字符特征和标准模板的字符特征，计算两者之间的相似性，相似性最大的标准模板的字符即为待识别的字符。该方法首先要建立标准模板库，其中标准模板库中的字符的大小是一样的；然后将待识别的字符规格化，其大小应该和模板库中的字符一样；最后将待识别的字符和标准模板库中的所有字符进行匹配，计算相似度。模板匹配字符识别算法适用于印刷字体、字体规范的字符等，但是对字符变形、弯曲、字符旋转等情况的抗干扰能力差。</p>
<p><strong>（2）神经网络字符识别算法</strong></p>
<p>　　主要思想是：通过神经网络学习大量字符样本，从而得到字符的样本特征。当对待识别的字符进行识别时，神经网络就会将待识别字符的特征和之前得到的样本特征匹配，从而识别出字符。该算法主要利用神经网络的学习和记忆功能。神经网络虽然有其优点，但是由于采用神经网络识别字符依赖于初始的样本的选择，并且容易陷入局部最优和收敛速度慢，因此采用神经网络识别字符的算法仍需要改进。</p>
<p><strong>（3）支持向量机</strong></p>
<p>　　主要思想：同上，都是先得到样本特征，进行训练，然后再分类。SVM应该算是用的的最多的分类方法，一般大多适合于二分类问题，在这里就需要使用多分类器来构造。</p>
<h3 id="字符识别步骤："><strong>字符识别步骤：</strong></h3>
<h4 id="1、归一化">1、归一化</h4>
<p>　　主要包括位置归一化和大小归一化。由于本文处理的车牌字符都是标准的印刷体字符，且都进行过倾斜校正，所以不需要对其进行位置归一化。但由于摄像距离大小不一样，导致拍摄到的车辆图像中的车牌字符大小不一，为了达到更好的识别效果，就需要对分割出来的单个车牌字符进行大小归一化。常用的归一化方法有两种：一种是将字符图像的外边框按比例线性放大或缩小到规定尺寸；另一种是根据水平和垂直两个方向像素的分布进行大小归一化。一般用第一种。当映射到原图像的点的坐标不是整数，即位于几个像素之间，这就需要利用插值算法来决定该像素的值。使用常见的双线性插值法。将图像归一化为32*64的。</p>
<h4 id="2、特征">2、特征</h4>
<p>　　根据上一篇的介绍，采用LBP特征来识别汉字，均匀网格特征来识别字母和数字。</p>
<h4 id="3、分类器">3、分类器</h4>
<p>　　SVM作为分类器。支持向量机的原理，其所涉及到的数学知识比较复杂，自己编程实现的话有一定难度。采用现成的支持 SVM 的工具箱，公认做的比较好的是台湾大学林智仁(Chih-Jen Lin)教授开发的 LibSVM，支持 SVM 的各种算法，可以解决回归和分类识别问题。LibSVM 不但提供了 Windows 系统的可执行文件，还提供了 C 语言的源代码，方便科研工作者根据自己的需要进行改进，而且还提供了Java、Matlab、C#、Ruthon 等语言的接口。当然可以直接调用opencv中的SVM工具。 </p>
<p>　　汉字的笔画很稠密，字符分辨率非常低:如果对车牌汉字字符进行二值化，将会丢失汉字的很多重要的结构信息，产生不必要的噪声，导致笔画断裂和笔画粘连等。</p>
<h4 id="4、二次识别">4、二次识别</h4>
<p>　　总的来说，单个字符的识别率比较高，容易识别错的主要是相近字符，解决这类问题的最佳办法就是二次识别。将相似字符中的一个识别出来后，便能确定其属于哪一类相近字符类别,利用区分相近字符的细节特征，将这个字符到专门识别这类相近字符的分类器中进行二次识别。车牌字符中相近字符主要有5类，分为为“0”、“D”、“Q”，“B”、“8”，“2”、”Z”，“5”、”S”和“A”、“4”。</p>
<p>　　(1) “0”、“D、“Q”</p>
<p>　　从字符图像中可以看出,它们的区分在左侧和右下角，其中“D”的左边为直线，黑色像素点较多，而“0”和“Q”的左边均为弧线,黑色像素点相对较少；字符“Q”的右下角的笔画丰富，黑色像素较多。具体局部特征如图：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr8.1.png" alt="0dq"></p>
<p> 　　(2)“B、8“</p>
<p>　　它们的区别在字符的左侧,“8”的左侧为弧线,而“B”的左侧为直线。具体局部<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr8.2.png" alt="b8"></p>
<p>　　(3) “2、Z”</p>
<p>　　它们的区别在字符的上方，“2”的上方为弧线，“Z”的上方为直线，具体局部特征。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr8.3.png" alt="2z"></p>
<p>　　(4)“5、S”</p>
<p>　　它们的区别在字符的上半部分，“5”的上半部分中，上方和左侧均为直线,而”S”的上半部分为弧线。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr8.4.png" alt="5s"></p>
<p> 　　(5)“A、4”</p>
<p>　　由于存在倾斜等情况,仅仅通过基本特征会出现误识别,它们的区别在左下角。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr8.5.png" alt="a4"></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>​第八篇：字符识别</p>
<p>　　车牌定位、车牌倾斜校正、车牌字符分割都是为车牌字符识别做的前提工作，这些前提工作直接关系到车牌识别系统的性能。车牌字符识别是车牌识别系统的核心部分，车牌字符识别的准确率是衡量车牌识别系统的一个很重要的指标。</p>
<p>　　一般字符识]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（七）-- 字符特征]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%83%EF%BC%89-%E5%AD%97%E7%AC%A6%E7%89%B9%E5%BE%81/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（七）-字符特征/</id>
    <published>2014-12-29T08:23:42.000Z</published>
    <updated>2014-12-29T08:29:16.000Z</updated>
    <content type="html"><![CDATA[<p>第七篇：字符特征</p>
<p>选择的字符特征应该满足以下条件：</p>
<p>　　（1）选取的字符特征具有较强的鲁棒性，不受字符变形、弯曲等影响。</p>
<p>　　（2）两个字符的字符特征不能完全相同，但部分相同是允许的，即选择的字符特征是唯一的，但是不能重复。</p>
<p>　　（3）选取的字符特征要尽可能的提供字符的信息。</p>
<p>　　（4）选择的字符特征提取方法易于实现，能够减少计算时间。</p>
<p>　　一般采用<strong>纹理、边缘特征</strong>。纹理特征是表示图像的另一种重要的视觉特征，纹理结构反映图像亮度的空间变化情况，具有局部与整体的自相似性。纹理是有纹理基元按某种确定性的规律或某种统计规律排列组成的，在纹理区域内各部分具有大致相同的结构。</p>
<h4 id="提取特征的的方法：">提取特征的的方法：</h4>
<p>　　（1）逐像素特征提取是指对整幅二值图像进行扫描，若图像中的像素点为黑色像素点时，则令特征值为 1，否则特征值为 0。经过该方法提取的特征向量的维数与图像中的像素点的个数相同。</p>
<p>　　（2）骨架特征提取是先细化字符图像，然后从细化后的字符图像中逐像素地提取特征。此方法适用不同大小的字符。</p>
<p>　　（3）垂直方法数据统计特征提取是首先对字符图像进行水平投影，统计水平投影值，此处的水平投影值为黑色像素的数目；然后通过对字符图像进行垂直投影，统计垂直投影值，此处的垂直投影值仍为黑色像素的个数；最后将水平和垂直投影值作为字符的特征向量。</p>
<p>　　（4）13 点特征提取方法的总体思路是：首先把字符平均分成 8 份，统计每一份黑色</p>
<p>　　像素点的个数作为 8 个特征。分别统计这 8 个区域中的黑色像素的数目，就可以得到 8 个特征；然后统计水平方向中间两行和垂直方向中间两列的黑色像素点的个数作为 4 个特征；最后统计所有黑色像素点的个数作为 13 个特征。</p>
<h4 id="常用的特征求取：">常用的特征求取：</h4>
<p><strong>一、粗网格特征：</strong></p>
<p>　　将归一化后的字符图像等分成 8×8 网格，统计各网格内黑像素的数量，取得一个 64 维的网格特征。</p>
<p>　　外围特征：提取字符外围特征的步骤为：</p>
<p>　　① 把归一化后的点阵图形等分为 8 行。</p>
<p>　　② 计算每一行中点从图像左边缘至第一项由白变黑的长度（如果没有由白变黑的点，则默认为零）。</p>
<p>　　③ 再计算每一行中点从图像左边缘至第二项由白变黑的长度（如果没有由白变黑的点，则默认为零）。</p>
<p>　　④ 仿照上面 3 个步骤，提取其它 3 个边缘的特征。</p>
<p>　　采用上述方法可以提取另一个 4×2×8=64 维的外围特征。</p>
<p>　　通过采用基于像素数量的粗网格特征与外围特征相结合方法可以提取字符的128 维特征，用以字符识别。</p>
<p><strong>​二、PCA进行汉字识别，网格特征进行数字和字母的提取。</strong></p>
<p>　　网格特征是指通过把二值化后的字符分成M×N个网格，统计每一个网格中的字符像素数量，把各个网格中的像素数量组合起来作为字符的网格特征来识别字符。字母数字相对于汉字来说笔画简单，也极少出现字符轮廓模糊的现象。因此，字母数字的识别相对来说比较简单。但是，字母数字之间存在相似字符的比例较高，而且相似字符之间的差异又比较小，很容易识别错。对字母数字的识别论文采用了二次识别的思想。</p>
<p><strong>三、均匀网格特征</strong></p>
<p>　　统计黑像素点在每个网格中所占的比例，属于统计特征中局部特征的一种，体现了文字点阵的整体形状的分布。它将字符图像二值化以后，再把样本字符图像分成mxn个M格，并统计每个网格中属于文字点阵的像数量，记为i；统计整个图像巾屈于文字点阵的像素数量，记为j；计算各个网格中的文字点阵的像素数量整个像中文字点阵的像素数量之比P=i/j将每个网格统汁的百分比P組合起来作为字符的统计特征，用以实现对字符的识别。好个网格屮的文字点阵比例反映了文字笔画在二维平面空间的分布特征。</p>
<p>　　网格特征的统计是以网格为单位进行的,即使个别像素点的统计有误差也不会对识别结果造成很大的影响，该特征还具有较强的区分相似字符的能力。此特征提取算法比较简单，计算速率很快,且易于实现,但其对字符图像配准要求较高，故需要在提取字符图像的特征之前，对图像进行去边框等预处理操作。此算法更适合印刷体等较规则的字体，而不适用于手写体。</p>
<p><strong>四、LBP特征进行汉字识别</strong></p>
<p>　　预处理模块对图像进行归一化操作；第二个模块计算出图像中每个像素点的LBP值；第三个模块用于将图像平均分割为MxN个网格；最后一个模块用于计算各块的LBP特征。</p>
<p>　　1、传统的LBP算法是基于3 X 3的窗口的，对应于9个灰度值。将该窗口的8邻域的灰度值与中心像素的灰度值比较，小于中心灰度值的像素点的置为0，反之将其置为1；然后，通过逆吋针或者顺时针将这8个二进制数转化为一个二进制序列，并求出其对应的十进制值，作为这个3X3窗口的中心像素点的特征值。即各像素点的LBP值。</p>
<p>　　2、将每个像素点的LBP值齊代它的灰度值,得到LBP阁像。并将LBP图像分块，对每个分块进行直方图统计。如,将LBP图像分为4<em>8块，每块大小为8</em>8。在每个分块内，将0-255的LBP值量化为32级，并进行直方图统计。即每个分块的LBP特征为32维。</p>
<p>　　3、将各个小块的LBP特征连起来，获得(4<em>8)</em>32=1024维的一个矢量，该矢量即为字符图像的LBP特征。</p>
<p>　　<strong>改进的LBP特征：</strong></p>
<p>　　均匀模式：它们有一个共同点，即在LBP二值编码序列巾，最多有两个0到1或1到0的变化。LBP二值编码序列为11000001，从1到0的变化为1次,从0到1的变化为1次，即它的均匀性U(LBP)=2。满足U(LBP)&lt;=2的所有模式称为均匀模式。在8邻域中，满足U(LBP)&lt;=2的所有模式的个数为8*(8-1)+2，具体的LBP二值编码序列与i/(Z及TMH]对应图见图2-16。再进一步将它们旋转到最小值后，具有旋转不变性的均勾模式(Rotation Invariant Uniform Pattern)的个数则为8+1。</p>
<p>　　模式对应的LBP二进制中从0变化为1和从1变化为0的次数之和小于等于两次，则该模式就是均匀模式。再根据顺时针或逆时针方向读出8个二进制数作为一个二进制序列,计算其对应的十进制值，作为该3*3矩形的中心元的特征值。反之，则该模式就不是均匀模式，它们的LBP值均为8+1。</p>
<p>　　由于改进的LBP特征是用58种均匀模式和统一后的一种非均匀模式来表示的。即在每个分块内，将0-255的LBP倍转化为59级。将这59级量化到0-63、64-127、128-191、192-255这四个区间中，并进行直方图统计。即每个分块的LBP特征为4维。</p>
<p>　　将各个小块的LBP特征连起来，获得(4*8)*4=128维的一个矢量，矢量即为字符图像的LBP特征。均匀模式时的LBP特征向量维数=图像分块数*59，改进的LBP特征向量维数=图像分块数*4，大大地提高了识别速率。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>第七篇：字符特征</p>
<p>选择的字符特征应该满足以下条件：</p>
<p>　　（1）选取的字符特征具有较强的鲁棒性，不受字符变形、弯曲等影响。</p>
<p>　　（2）两个字符的字符特征不能完全相同，但部分相同是允许的，即选择的字符特征是唯一的，但是不能重复。</p>]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（六）-- 字符分割]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%85%AD%EF%BC%89-%E5%AD%97%E7%AC%A6%E5%88%86%E5%89%B2/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（六）-字符分割/</id>
    <published>2014-12-29T07:56:00.000Z</published>
    <updated>2014-12-29T08:17:23.000Z</updated>
    <content type="html"><![CDATA[<p>第六篇：字符分割</p>
<p>　　在知道了车牌字符的规律之后，可以根据车牌的特点对字符进行分割。一般最容易想到的方法就是根据车牌投影、像素统计特征对车牌图像进行字符分割的方法。是一种最常用的、最基本的、最简单的车牌字符分割方法。它的精髓是对车牌图像进行逐列扫描，统计车牌字符的每列像素点个数，并得到投影图，根据车牌字符像素统计特点（投影图中的波峰或者波谷），把车牌分割成单个独立的字符。</p>
<p>　　图像的边缘信息一般都是高频信息，所以在水平、垂直方向上对车牌图像进行小波变换，对其高频信息进行重构，获得相应的高频信息方面的子图，在车牌垂直投影图像中找到每个车牌字符的边界所在位置，并记下边界位置的横坐标；同理在水平投影图像中找到相应的边界的纵坐标，再根据相应的字符坐标值将字符分割出来。</p>
<p>　　一般在进行分割之前需要对车牌进行预处理：倾斜校正和去噪处理。</p>
<p>　　在进行分割之后需要统一字符大小，对其进行归一化和去边框处理。</p>
<p><strong>（1）统一车牌底色：</strong></p>
<p>　　对不同类型的车牌灰度图像进行二位化以后，有的呈现的是黑底白字，而有的则是白底黑字，为了便于对字符进行分割，需首先将不同种类车牌的二值化结果进行景颜色和目标颜色的统一，然后再用相关字符分割的方法对车牌屮的字符进行切分和提収。统一车牌底色可以有两种方法：</p>
<p>　　基于颜色分量的判断，但由于我国车牌种类太多，这个方法并不能完全区分，但是区分两种车牌类型还是可以的，例如蓝底白字车牌中的R小于B，而黄底黑字中的B大于R，在考虑到光照影响和使用已久褪色车牌上这种方法就不好了。</p>
<p>　　基于二值图像中像素比例特征的车牌底色判断：一般情况下，二值化后的车牌图像中字符笔画的像素个数在整个车牌的像素数目中所占的比例要小于50%。因此，可以通过分别计算二值化后的车牌中两种像素值的像素个数的大小来判断是否需要反色，若目标像素的比例大于50%，则将图像进行反色，否则不进行处理。这种方法的优点是算法简单，适用各种底色类型的车牌。缺点是若车牌中含有的字符的笔画较粗或者是车牌上存在较多污点或者是有装饰物等因素影响时，往往不能准确的判断底色。</p>
<p><strong>（2）图像去噪</strong></p>
<p>　　采集的图像总是会受到各种噪声的影响。为了保证后续处理的精确度，需要抑制图像中的噪声。对二值化后的车牌图像进行中值滤波处理，它是一种常见的非线性滤波方法，是一种局部平均的图像平滑技术，也是一种低通滤波。经典的中值滤波算法步骤如下：</p>
<p>　　1、令一个 3*3模板沿行或者列方向的移动；</p>
<p>　　2、每次移动后，对模板覆盖区域的像素灰度值进行排序；</p>
<p>　　3、用排序得到的中值代替模板内中心位置的原始图像像素灰度值。</p>
<p>　　通过以上步骤可以看出，中值滤波的主要功能就是让与周围像素灰度值的绝对差较大的像素改为与周围像素灰度值接近的灰度值，去除那些相对于其领域像素更亮或更暗的灰度。一般来说，小于中值滤波器模板面积一半的亮或暗区域会被滤掉，而较大的物体则会几乎原封不动的保留下来。</p>
<p><strong>（3）倾斜校正</strong></p>
<p>　　通常车牌区域的上下沿是两条明显的平行直线，一般都采用Hough 变换，检测出这两条直线的倾斜角，然后对车牌进行校正。然而传统的 Hough变换是对整幅图像的每个像素进行计算，以求出图像中可能存在的直线。</p>
<p>　　要想使用 Hough 变换计算车牌的倾斜角度，必须先确定进行 Hough 变换所需要的数据，即车牌的边缘点。如果图像包含完整的车牌，一般采用检测车牌的上下边框边缘点来作为 Hough 变换的数据，但由于实际得到的车牌不一定含有边框或者只有极少量的边框，所以最常用的是直接检测车牌每个字符上下边缘点作为Hough 变换的数据来源，但是由于实际中得到的车牌含有噪声、污损等原因，用这种方法会产生大量的干扰点，影响校正效果。</p>
<p>　　方法：对车牌图像在垂直方向进行投影并用高斯滤波器进行平滑，定位投影曲线中的所有波谷点，然后在相应的二值图中，查找所有波谷点之间最高的连通区域，得到的各个区域大部分就是车牌中的各个字符，最终选取各个连通域中即字符的最高和最低点作为 Hough 变换的检测点。对图像进行旋转时采用双线性插值。 </p>
<p><strong>（4）去边框</strong></p>
<p>　　定位出来的车牌图像往往会包含车牌的部分或者全部边框，甚至还包含部分车身，为车牌字符分割带来了不利影响。因此就需要先对车牌图像进行去边框处理，其原理如下：采用水平投影得到上下边界。</p>
<p><strong>（5）字符分割</strong></p>
<p>　　采用一种基于相邻字符最大间隔宽度的方法来对车牌中的字符进行分割。由单行车牌的特点可以知道，在第二个字符和第三个字符之间存在一个圆形的间隔符，且该间隔符在每个单行车牌中有且仅有一个，还有一个重要的特点就是此间隔符所在的间隙约是其他相邻字符之间间隙的2.6倍，是整个车牌图像中相邻字符的最大间隙，根据这一先验知识首先确定了第二个字符右边缘和第三个字符左边缘的位置，然后由二值图像的垂直投影及单个字符的高宽比确定后5个和前2个字符的精确位置，因此，该方法的最为关键的部分是寻找图像中间隔符所在的空隙。</p>
<p>　　采用连通域和投影相结合的方法来对车牌图像进行字符分割，采用四连通标记法对车牌字符边界进行标记，形成连通域；然后判断各个区域的高宽是否基本等于车牌字符区域的高宽（去边框时已经求出），若相差较大时，就进行垂直投影，把宽小于车牌字符宽的相邻区域进行合并，把宽大于车牌字符宽的相邻区域进行进一步分割；最后对各个区域加矩形边框，提取单个车牌字符。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr6.jpg" alt="分割"></p>
<p>　　在理想的情况下，波谷的值应该为零，并且两个字符之间应该存在波谷，但是由于受到噪声的干扰，使得波谷的值为非零。常见的字符分割的问题有：字符粘连、字符断裂、数字“1”。字符粘连是指两个以上的字符连在一起，在垂直投影上的表现是原本应该为波谷的地方，现在却为非零的垂直投影值；字符断裂是一个字符分裂为几部分，在垂直投影上的表现为几段垂直投影；数字“1”的垂直投影值比较小，容易误判为噪声。可以结合车牌中字符的几何特征解决上述问题。设车牌中字符的宽度为 Width。</p>
<p>　　1）字符粘连</p>
<p>　　当 Width&lt; charWdith &lt; 1.5<em>Width，其中 charWidth 为粘连字符的宽度。此时为两个字符粘连的情形。可取 charWidth / 2 作为单个字符的宽度，以此来分割两个粘连的字符；若 1.5</em>Width&lt; charWidth&lt; 2*Width，此时为三个字符粘连的情况。通过单个字符具有固定的宽高比的先验知识，利用字符的高度求出字符的宽度。然后根据字符的宽度对粘连的字符进行分割。</p>
<p>　　2）字符断裂</p>
<p>　　若 charWidthi&lt; 0.5<em>Width 且 0.5</em>Width &gt; charWidthi+1。其中 charWidthi为当前字符的宽度，charWidthi+1为下一个字符的宽度。此时把当前字符和下一个字符合并。</p>
<p>　　3）数字“1”</p>
<p>　　当 charWidthi&lt; 0.5<em>Width 且 0.5</em>Width &lt; charWidthi+1时，统计区间宽度 charWidthi内的投影值大于 0.8*Height 的个数 nums，其中 Height 为车牌图像的高度。当符合条件 nums ≥ Thresh 时，其中 Thresh 为阈值，此时判定为数字“1”，否则为噪声。</p>
<p>　　<em>采用的车牌字符分割方法；对车牌图像进行灰度化处理，去除颜色信息，使后面的字符分割算法运行速度更快；对灰度车牌图像进行二值化处理（otsu），并统一车牌图像的背景和字符的颜色；对有一定倾斜角度的车牌图像进行倾斜校正处理，对车牌图像进行去边框处理；采用连通域与投影法相结合的方法对车牌图像进行字符分割，为后面的单个字符识别做准备。</em></p>
<p>​</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>第六篇：字符分割</p>
<p>　　在知道了车牌字符的规律之后，可以根据车牌的特点对字符进行分割。一般最容易想到的方法就是根据车牌投影、像素统计特征对车牌图像进行字符分割的方法。是一种最常用的、最基本的、最简单的车牌字符分割方法。它的精髓是对车牌图像进行逐列扫描，统计车牌字]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（五）-- 一种车牌定位法]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%BA%94%EF%BC%89-%E4%B8%80%E7%A7%8D%E8%BD%A6%E7%89%8C%E5%AE%9A%E4%BD%8D%E6%B3%95/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（五）-一种车牌定位法/</id>
    <published>2014-12-29T07:52:14.000Z</published>
    <updated>2014-12-29T07:53:15.000Z</updated>
    <content type="html"><![CDATA[<p><strong><em>该方法是某个文章中看到的，有点忘了是那一篇了，看的太多也太久了。</em></strong></p>
<p><strong>Step1、把采集到的RGB图像转换为HSI图像。</strong></p>
<p>　　HSI模型能反映人对色彩的感知和鉴别能力，非常适合基于色彩的图像的相似比较，故采用HSI模型。假设HSI颜色模型各分量为H、S、I ，RGB 彩色模型的各个分量为 R,  G ,B ，则 RGB 转换 HSI 的公式为：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr5.1.jpg" alt="公式1"></p>
<p>　　其中H表示色调，如红色、绿色、蓝色等，色调的取值范围为[0,360]，其对应颜色轮的角度。S表示饱和度，其意义是颜色的鲜艳度，可以用百分比来表示，从0%到完全饱和100%。 I表示亮度，是指颜色的明亮程度，通常用百分比表示，从黑0%到白100%。</p>
<p>　　通过式把 RGB 彩色图像转换为 HSI 彩色模型的图像，HSI 彩色模型的图像，左侧为 RGB 彩色图像。从 HSI 颜色的图像中可以看出，高亮部分为车牌的蓝色区域。</p>
<p><strong>Step2、提取 HSI 图像中的 H、S 分量。</strong></p>
<p>（1）利用 H 分量进行图像颜色分割。由于蓝色的 H 分量值为 240 º，并且图像可能受到噪声污染，所以蓝色的 H 分量值有一定的波动。经过实验可得到蓝色分量 H 的最小值blue_MinH 为 220º，最大值 blue_MaxH 为 245º。假设二值图像为 Bw，Bw 和 HSI 图像具有相同的大小，Bw 中的所有元素都为 0。利用下式把满足蓝色区域条件的设为前景白色，即 Bw = 1；不满足条件的设为背景黑色，即Bw = 0。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr5.2.jpg" alt="公式2"></p>
<p>（2）利用S分量对图像处理。因为受到天气、光照等条件的影响，非牌照区域也会和牌照区域的色调特征相同，因此可以利用 S 分量去掉饱和度小且满足蓝色色调范围的区域。设饱和度的阈值为 threshS，利用去掉满足蓝色色调条件但非车牌的区域。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr5.3.jpg" alt="公式3"></p>
<p><strong>Step3、利用车牌的几何特征去除候选区域中的非牌照部分。</strong></p>
<p>　　由于天气、光线等因素导致采集到的图像受到噪声的干扰，所以即使经过 Step1、Step2 的处理，仍然可能存在多个车牌的候选区域。利用车牌的几何特征可以过滤掉部分不符合条件的候选区域。常用的车牌几何特征有：候选区域的面积、外接矩形的宽度和高度、外接矩形的长宽比，本文采用候选区域的高度。具体做法如下：通过对 Step2 得到的二值图像 Bw 水平投影，得到水平投影图，其中水平投影值是同一行中的像素点的个数。基于车牌区域存在一定的高度的事实，设定车牌高度的最小值为 Height_Min,最大值为 Height_Max,候选区域的高度为 Heigh。当满足 Height_Min ≤ Height ≤ Height_Max 时，从图像中提取出高度为 Height 的候选区域。</p>
<p><strong>Step4、为处理车辆和车牌颜色特征相同的情况，可以通过特征颜色边缘检测去除和车牌颜色特征相同的伪车牌区域。</strong></p>
<p>　　设图像 K(i,j)= (H(i,j),S(i,j), I(i,j))，其中 H(i,j),S(i,j), I(i,j)分别表示 K(i,j)的 H、S、I 分量。二维数组 K2(i,j)是边缘检测后的图像。采用以 K(i,j)为中心的 3×3窗口检测特定的颜色边缘。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr5.4.jpg" alt="公式4"></p>
<p>（1）在 HSI 彩色模型中，满足式前两式时判为蓝色；满足式（2.4）则为白色。<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr5.5.jpg" alt="公式5"></p>
<p>（2）获取蓝白边缘图像。判断蓝白边缘的条件为：（a）K(i-1,j-1)、K(i,j-1)、K(i+1,j-1)都为蓝色像素点，K(i-1,j+1)、K(i,j+1)、K(i+1,j+1)均为白色像素点；（b）K(i-1,j-1)、K(i,j-1)、K(i+1,j-1)都为白色像素点，K(i-1,j+1)、K(i,j+1)、K(i+1,j+1)均为蓝色像素点。若满足（a）、（b）中的任意一个条件，则 K(i-1,j)、K(i,j)、K(i+1,j)为蓝白边缘点，令 K2(i-1,j)= K2(i,j) = K2(i+1,j) = 1，并将该窗口中的 K2 其它像素设为 0；若以上条件均不满足，则将该窗口位置的 K2 中的所有像素值置为 0。同时将窗口遍历整幅图像，得到蓝白边缘图。</p>
<p>（3）利用车牌的几何特征去掉不符合条件的候选区域。面积大小的计算定义为：蓝白边缘图像中白色的像素点的总数，即为 white_CountTotal。设车牌区域面积的最小值为 min_Area，最大值为 max_Area。当 min_Area ≤ white_CountTotal 并且 white_CountTotal ≤ max_Area,则认为是车牌区域。</p>
<p><strong>Step5、确定车牌区域的宽度。</strong></p>
<p>　　经过前面的步骤已得到车牌区域，确切的说应该是车牌的高度，所以还需得到车牌的宽度。本文采用垂直投影的方法确定车牌的宽度。对车牌区域进行垂直投影。垂直投影值定义为图像中同一列为白色像素点的个数，记为vertical_Count，令垂直投影值的阈值为 verticalValue_Thresh。</p>
<p>　　具体过程如下：</p>
<ul>
<li>首先从图像的最左边扫描图像的垂直投影值，当 vertical_Count ≥verticalValue_Thresh时，该位置即为车牌区域的起点 wide_Start ；</li>
<li>然后继续扫描直到vertical_Count ≤ verticalValue_Thresh 时，此位置则为车牌区域的终点 wide_End；</li>
<li>最后得到车牌区域的宽度 wide = wide_End – wide_Start。</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong><em>该方法是某个文章中看到的，有点忘了是那一篇了，看的太多也太久了。</em></strong></p>
<p><strong>Step1、把采集到的RGB图像转换为HSI图像。</strong></p>
<p>　　HSI模型能反映人对色彩的感知和鉴别能]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（四）-- 车牌定位]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E5%9B%9B%EF%BC%89-%E8%BD%A6%E7%89%8C%E5%AE%9A%E4%BD%8D/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（四）-车牌定位/</id>
    <published>2014-12-29T07:24:23.000Z</published>
    <updated>2014-12-29T07:37:06.000Z</updated>
    <content type="html"><![CDATA[<p>第四篇：车牌定位　　</p>
<p>　　车牌定位就是采用一系列图像处理或者数学的方法从一幅图像中将车牌准确地定位出来。车牌定位提取出的车牌是整个车牌识别系统的数据来源，它的效果的好坏直接影响到整个系统的表现，只有准确地定位出车牌，才会有后续的车牌分割与字符识别。</p>
<p>　　目前车牌定位有两大类、基于灰度、基于彩色。</p>
<h4 id="基于灰度：">基于灰度：</h4>
<p>　　我们采用的是<strong>基于灰度的形态学的车牌定位</strong>：首先根据车牌区域中丰富的纹理特征，提取车牌图像中垂直方向的边缘并二值化。然后对得到的二值图像进行数学形态学(膨胀、腐烛、幵闭运算等)的运算，使得车牌区域形成一个闭合的连通区域。最后通过车牌的几何特征(高、宽、宽高比等)对得到的候选区域进行筛选，最终得到车牌图像。</p>
<p>　　<strong>基于灰度的还有边缘检测的车牌定位</strong>：由于车牌字符的灰度值与车牌底色的灰度值相差较大，字符与底色的交界处就有灰度突变，灰度突变处就会产生边缘，这是车牌定位技术中非常重要的特征。也可以通过检测车牌的外边框来定位车牌，由于外边框的上下左右四边都为直线，而且有明显的边缘特征，所以首先利用边缘检测算法提取车牌边框位置，然后，用Hough变换算法检测直线，确认外边框的上下左右四条边位置就确定了车牌在图像中的位置。</p>
<p>　　<strong>基于投影法的车牌定位方法</strong>：首先对车牌图像进行二值化，由于车牌区域存在明显的剧烈的字符与背景的灰度跳变，将跳变次数投影到垂直轴上，那么车牌区域对应的垂直轴上会有一个明显的峰值，这样可以得到车牌的上下边界。然后对上下边界内的区域进行水平投影，字符区域会出现明显的峰值，这样可以得到车牌的左右边界。这种方法比较理想化。</p>
<p>　　<strong>基于纹理分析的车牌定位方法</strong>：所谓的纹理特征是指对图像进行扫描得到的灰度变化曲线，由于扫描经过车牌得到的变化曲线明显不同于经过非车牌得到的曲线，根据这个特点再结合形态学操作和其它先验知识就能从图像中提取出车牌。</p>
<h4 id="基于彩色的：">基于彩色的：</h4>
<p>　　从颜色空间的角度来看，HSV (Hue色调，Saturation饱和度，Value亮度)颜色空间具有线性伸缩性，比RGB颜色空间更容易区分色彩。HSV车牌定位典型的思路是首先将车牌图像从RGB空间转换到HSV空间，然后寻找图像中含有蓝白相间、黄黑相间、白红相间和白黑相间的地方，对得到的候选区域进一步用字符颜色提取车牌字符，最后用车牌的字符特征确定车牌位置。基于彩色图像的车牌定位方法对字符颜色和背景颜色固定的车牌可以取得较好的效果。</p>
<p>　　<strong>基于彩色图像的边缘检测和区域生长相结合的车牌定位</strong>：实现该方法的基本思想是：首先可以利用边緣检测算子对原始彩色(RGB空问)图像进行边缘检测，使得车牌区域的纵向纹理特征得到增强；接着利用数学形态学中的膨胀算法实现区域的连通，然后采用区域生长的方法对候选区域进行标记，最后利用车牌具有的特征和字符排列的频率特点，去除伪车牌区域，得到车牌区域。</p>
<p>　　<strong>基于纹理和颜色综合特征的车牌定位</strong>：首先将原始彩色图像M0的颜色空间转化到HSV颜色空间Ml；接着对Ml进行色彩分割，把所需要的颜色的区域设置为前景白色，其他区域设为背景黑色，此时得到图像M2，其次对M2采用区域生长的方法进行处理，并生成连通区域，得到车牌区域的集合A，然后若集合A中不包含车牌，则继续对Ml进行色彩分割，提取下一块前景颜色区域，并对该区域进行车牌特征分析，重复上述过程。</p>
<p>　　<strong>车牌轮廓特征判断条件</strong>：</p>
<pre><code>（1）外接轮廓的高度大于5个像素或小于25个像素

（2）外接轮廓的宽度大于20个像素或小于80个像素

（3）外接轮廓的宽高比大于2或小于10
</code></pre><p> 　　由于我国车牌种类繁多，颜色组合不一致，会遇到以下问题：一方面各地发放的车牌的底色色调会有所不同，另一方面受自然光照变化影响，采集到车牌图像的色度的变化范围也很大。因此，定位我国车牌的方法不适宜直接利用颜色信息进行定位。</p>
<p>　　其实，还有一些文献里提出<strong>支持向量机和adaboost等分级分类的定位方法</strong>，虽然使用训练的方法可以很准确的得到车牌图像，但是实际中由于环境的复杂性，单纯的一种方法并不不能得到很好的结果。对图像进行预处理，结合三次定位，像素统计粗定位，颜色阈值定位，文理特征定位，一次次的精确定位结果，调整参数，知道得到正确的车牌图像。</p>
<p>　　这里有涉及到边缘检测的应用，其中边缘检测就有几种常用的算子方法。还涉及颜色空间的转换，这里不做具体展开。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>第四篇：车牌定位　　</p>
<p>　　车牌定位就是采用一系列图像处理或者数学的方法从一幅图像中将车牌准确地定位出来。车牌定位提取出的车牌是整个车牌识别系统的数据来源，它的效果的好坏直接影响到整个系统的表现，只有准确地定位出车牌，才会有后续的车牌分割与字符识别。</p>
<]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（三）-- LPR系统整体结构]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%89%EF%BC%89-LPR%E7%B3%BB%E7%BB%9F%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（三）-LPR系统整体结构/</id>
    <published>2014-12-29T07:14:11.000Z</published>
    <updated>2014-12-29T07:23:27.000Z</updated>
    <content type="html"><![CDATA[<p>第三篇：系统的整体架构</p>
<p>　　LPR系统大体上可由图像采集系统，图像处理系统，数据库管理系统三个子系统组成。它综合了通讯、信息、控制、传感、计算机等各种先进技术，构成一个智能电子系统。</p>
<p><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr3.jpg" alt="LPR整体结构"></p>
<p>　　<strong>图像采集系统</strong>：图像采集系统主要由传感器、辅助照明设备和图像采集设备组成，主要功能是采集车辆图像。当有车辆经过时会触发感应装置，感应装置一般为地感线圈，触发成功后摄像机或照相机会自动采集当前的图像，最后将采集到的图像传送到计算机或手持的嵌入式系统进行处理。</p>
<p>　　<strong>图像处理系统</strong>：图像处理系统即为本文主要讨论的算法处理模块，为整个系统的软件部分。它主要包括图像预处理、车牌定位、字符分割和字符识别四个部分，它的任务是运用数字图像处理、模式识别等学科对获得的车辆图像进行处理以获得车牌上的字符内容信息，后面章节讲对它每一个部分做一个粗略的介绍。</p>
<p>　　<strong>数据管理系统</strong>：数据管理系统是一个后端管理数据库，它包含了几乎所有的图像输入是指利用摄像机或者数码相机采集到的车牌图像。车牌图像的质量与采集图像的设备和实际环境有关。性能好的摄像机能够得到质量更好的车牌图像，有利于识别车牌图像中的字符。在光照不均、恶劣天气的环境下，采集到的车牌图像的像质较差，导致车牌识别系统的性能降低。车牌登记信息，车牌中的字符信息被识别出来后就输入到这个系统进行查找对比，以方便公安机关追查被盗车辆，打击犯罪分子。</p>
<p>　　其中<code>图像处理模块</code>主要包括六个部分：<code>预处理</code>、<code>车牌定位</code>、<code>倾斜校正</code>、<code>字符分割</code>、<code>字符识别</code>。其中，<strong>车牌定位</strong>、<strong>字符分割</strong>、<strong>字符识别</strong>是车牌识别的关键技术。流程图如下：</p>
<p><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr4.jpg" alt="识别算法流程"></p>
<p>　　<strong>图像预处理</strong>是指对采集到的图像进行二值化、边缘检测、去除噪声、图像灰度化等操作。经过预处理的车牌图像增能够强目标图像，提高目标和背景图像的对比度，方便车牌识别的后续工作。</p>
<p>　　<strong>车牌定位</strong>是从一幅拍摄到的图片中定位出车牌的位置，并从图片中提取出车牌图像。车牌定位正确与否直接影响到字符分割和识别的工作，是所有关键技术中的第一步。</p>
<p>　　<strong>倾斜校正</strong>是指检测车牌图像的倾斜角度，并校正车牌图像。倾斜的车牌图像会导致车牌中的字符倾斜，直接影响到车牌字符的分割和识别，因此必须对倾的车牌图像进行校正。</p>
<p>　　<strong>字符分割</strong>是对提取出的车牌图像进行切割，从车牌图像中提取出单个车牌字符的图像。由于字符识别是以分割出的单个字符为输入，所以字符分割的准确与否直接影响到字符识别。</p>
<p>　　<strong>字符识别</strong>是指对分割出的字符进行处理，识别出车牌中的字符。因为我国的车牌号码的字符包含：汉字、英文字母、数字，增加了对字符识别的难度。字符识别直接影响到整个车牌识别系统结果的准确性。</p>
<p>　　这是一个LPR系统最基本的结构组成，每个模块的功能也清晰的给出来了，这对于后续我们的分工有很大的帮助，模块与模块之间耦合度也比较小。</p>
<p>　　<em>基于Linux的车牌识别系统，界面基于qt开发，图像处理模块基于opencv，数据库使用的mysql，基本上是在原有的系统上进行修改。原有的系统是在window平台下，使用MFC，opencv的版本是之前的C版本，按照新的架构重新修改代码，数据库部分基本没变，重点更新的是图像处理部分。</em></p>
<p>　　最后，在开发 LPR 算法之前，要<strong>确定算法的目的和要求</strong>。LPR 算法的最终目的是识别车辆的车牌号码，所以识别正确率自然是系统设计中应该首要考虑的因素。影响识别正确率的因素有很多，主要的有以下几点：一是定位的准确性；二是识别前字符的预处理；三是字符识别的算法。为了提高识别正确率，需要对现有的车牌字符识别算法进行改进，在后面的章节中会有详细的介绍。</p>
<p>　　其次，LPR 算法在工作时需要实时处理交通流量信息，所以系统的工作效率——即识别时间也是系统设计时必须要考虑的因素，一般要求在 1s 内能够完成识别，这就要求识别算法的复杂度、运算量不能太大。</p>
<p>　　除了算法识别正确率和识别时间外，算法软件的操作界面应尽量简单、友好，还要考虑系统的无故障运行时间，系统体积的大小等因素。最后，算法设计要面向现场、面向终端客户的需求，考虑到 LPR 系统在户外工作，所以要克服外面环境的复杂性及光照条件的变化，设计出一套适应性较强的算法。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>第三篇：系统的整体架构</p>
<p>　　LPR系统大体上可由图像采集系统，图像处理系统，数据库管理系统三个子系统组成。它综合了通讯、信息、控制、传感、计算机等各种先进技术，构成一个智能电子系统。</p>
<p><img src="http://7te8s4.com1.z0]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（二）-- 车牌特征及难点]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%BA%8C%EF%BC%89-%E8%BD%A6%E7%89%8C%E7%89%B9%E5%BE%81%E5%8F%8A%E9%9A%BE%E7%82%B9/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（二）-车牌特征及难点/</id>
    <published>2014-12-29T07:01:47.000Z</published>
    <updated>2014-12-29T07:12:37.000Z</updated>
    <content type="html"><![CDATA[<p>第二篇：车牌的特征及难点分析</p>
<h3 id="2-1_对我国车牌的认识">2.1  对我国车牌的认识</h3>
<p>　　我国目前使用的汽车牌号标准是 2007 年开始实施的《中华人民共和国机动车号牌》GA36-2007（2010 年修订）。根据 GA36-2007 对机动车牌号编排规则规定，我国汽车的车牌构造特点如下：</p>
<p>　　汽车车牌号的编排规则：我国的标准车辆车牌是由一个省份汉字（军警车牌为其他汉字）后跟字母或阿拉伯数字组成的 7 个字序列。标准车牌的的具体排列格式是：X1X2·X3X4X5X6X7，X1是各省、直辖市的简称或军警，X2是英文字母，代表该汽车所在地的地市代码，比如 A 代表省会，B 代表该省的第二大城市，C 代表该省的第三大城市，X3X4X5X6X7为英文字母或阿拉伯数字，2010年以前车牌号码的分布规律是，前面是字母，后面是数字。但是，随着车辆保有量的增加，每个字母所属号段越来越不够用。按照新《中华人民共和国机动车号牌》（2010 年修订）标准，将允许字母在后五位编码中任意一位出现，但不能超过两个。除了第一个汉字外，字母和数字的笔画在竖直方向都是联通的。</p>
<p>牌照类型如下图：<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr1.jpg" alt="拍照类型"></p>
<p>　　绝大部分的汽车牌照的宽度为1100px，高度为350px，牌照上一共有7个或8个字符，其中，每个字符的宽度为45mm，高度为90mm，间隔符的宽度为10mm，除了第二个和第三个字符之间的间距为 34mm 外，字符之间的间隔宽度12mm。民用的汽车牌照上有所属省、自治区或直辖市的简称(军用、警察牌为其他汉字)，监督机关及发证照的代号(大写的英文字母)后跟阿拉伯数字或英文字母组成的7个字符序列。<br>　　<br><img src="http://7te8s4.com1.z0.glb.clouddn.com/lpr2.jpg" alt="车牌"><br>　　<br>　　可以简单的归纳为以下特征：</p>
<p>　　1、颜色特征：即前面的六种类型，采用了对比度较为强烈的两种颜色的组合使车牌能明显区分于其它物体，而且车牌边框为白色或黑色两种颜色。使领馆车牌中的“使”和“领”字为红色，港澳出入境车牌中的“港”和“澳“两字为白色。警用汽车摩托车为白底黑字组合，其中”警“字为红色。</p>
<p>　　2、车牌具有统一的标准尺寸，这便于字符的分割和车牌的定位。</p>
<p>　　3、边缘特征：汽车的车牌边框是有规则的边缘，由于汽车车牌的字符排列规则，汽车车牌的垂直边缘比水平边缘更为丰富，而汽车的车身却有丰富的水平边缘，垂直边缘不明显。</p>
<p>　　4、黑白跳变特征：车牌区域二值化后，字符和背景为一黑一白，存在明显的黑白跳变，且跳变的次数在一定范围内。</p>
<p>　　5、投影特征：汽车车牌图像进行垂直投影后的图像是由波峰、波谷交替组成的连续分布图，垂直投影后的图像会有约七个波峰或波谷区；汽车车牌图像进行水平投影后的图像中灰度跳变的像素点数累加值很大。</p>
<p>　　了解我国车牌的特征，有利于后续对车牌进行的各种操作，在项目步骤中，这属于对需求目标的全面了解。对车牌的了解不能跳过，因清楚的知道我们所要处理的的目标的各个特性，这样才有利于我们利用这些特性来操作车票图像。</p>
<h3 id="2-2_技术难点">2.2 技术难点</h3>
<h4 id="2-2-1、车牌定位中的难点">2.2.1、车牌定位中的难点</h4>
<p>　　从环境等客观因素上来说，汽车的类型有很多且构造不同，使得不同汽车上的悬挂车牌的位置就会不同。这样，汽车车身与车牌区域出现相似的颜色、纹理，就很可能会造成车牌定位出错或需更长的时间才能定位出车牌。</p>
<p>　　车牌定位是指从拍摄的含有车牌的图像中定位出车牌的淮确位置，然后进一步的提取出车牌图像。其主要的难点有：</p>
<ul>
<li>周围环境因素，比如随机噪声，天气气候(雪天，雨天，雾天等)，光线(白天强光，晚上漆黑等)等。</li>
<li>车牌自身因素，比如车牌倾斜，字迹模糊，车牌乱挂装饰物，车牌周围广告标语覆盖或干扰等。</li>
</ul>
<h4 id="2-2-2、字符分割中的难点">2.2.2、字符分割中的难点</h4>
<p>　　字符分割是指从含有字符的车牌图像中将字符分割出来，字符分割的好坏会直接影响到下一步的字符识别。其主要的难点有：</p>
<ul>
<li>光照影响，不的照射光源(车灯，太阳光或辅助光源)，不同的气候条件(雨雪阴晴)，不同的光照角度。</li>
<li>汽车由于长途奔袭，再加上风吹日晒等各种原因，车牌上的字符可能会粘连，缺损或断裂，这会给字符分割带来一定的麻烦。</li>
<li>缺乏统一的车牌标准，车牌主要包括普通车牌，外事车牌和军用车牌等，这些车牌的规格，适用范围和颜色各有不同。</li>
</ul>
<p>实际应用中，摄像设备所放的方位和角度有可能造成拍摄出来的车牌图像倾斜、畸变或部分被遮挡；当汽车处于高速行驶时，所拍摄的车辆图像清晰度不高；背景复杂的车辆图像，定位会有一定的困难，对后续的字符分割和字符识别带来严重的困难。</p>
<h4 id="2-2-3、字符识别中的难点">2.2.3、字符识别中的难点</h4>
<p>　　字符识别是指将分割好的字符图像送到分类器中，对图像中的字符进行识别。字符识别是整个车牌识别系统中的最后一步，也是最为关键的一步。主要的难点有：</p>
<ul>
<li>车牌汉字中繁多的字符笔画，汉字较字母和数字的识别难度较大。</li>
<li>字符图像的分辨率较低时使得字符笔画结构特征不明显，特征难以提取。 </li>
<li>相似字符的识别(B和8，D和0等)。</li>
</ul>
<p>从算法上来说，由于采集到的车辆图像质量不高，存在噪声、图像模糊失真、车牌污损、其它字符区域干扰等情况，车牌识别技术中定位、分割、识别实现起来都有很多困难。算法的简捷、实用、快速往往和算法的速度形成冲突。怎样提高现有算法的识别率和速度，如何利用车牌的彩色信息进行车牌识别，一幅图像中多个车牌的情况怎样识别，怎样满足系统实时性要求等，这些都是车牌识别有待研究和解决的问题。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>第二篇：车牌的特征及难点分析</p>
<h3 id="2-1_对我国车牌的认识">2.1  对我国车牌的认识</h3>
<p>　　我国目前使用的汽车牌号标准是 2007 年开始实施的《中华人民共和国机动车号牌》GA36-2007（2010 年修订）。根据 GA36-2007]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[车牌识别LPR（一）-- 研究背景]]></title>
    <link href="http://silencewt.github.io/2014/12/29/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%ABLPR%EF%BC%88%E4%B8%80%EF%BC%89-%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF/"/>
    <id>http://silencewt.github.io/2014/12/29/车牌识别LPR（一）-研究背景/</id>
    <published>2014-12-29T06:48:22.000Z</published>
    <updated>2014-12-29T06:53:24.000Z</updated>
    <content type="html"><![CDATA[<p>　　在年尾用了几天的时间将2014年的所有工作都总结了一遍，将之前的文档综合了下。</p>
<p>　　以下是LPR系统，车牌识别的一些总结资料。</p>
<p>第一篇：LPR研究背景</p>
<p>　　汽车的出现改变了以往出行徒步和以马代步的时代，极大地改变了人们的生活方式，扩大了人们的活动范围，加强了人与人之间的交流。全世界的汽车拥有量呈爆炸性增长，汽车虽方便了我们的出行，但同时也造成了城市交通压力，应用现代科技解决汽车不断增长而出现的交通问题已经成为一项重要的研究课题，智能交通系统应孕而出。</p>
<p>　　智能交通系统(Intelligent Transportation System，简称 ITS)是一种充分利用各种先进的高新技术来实现实吋、准确、高效的交通管理系统，使交通更畅通更安全，它也是一种交通信息服务系统，使人们出行更方便更快捷。随着智能交通系统的快速发展，智能交通系统已经融入人们的日常生活，使人们的生活越来越方便。车辆是智能交通系统中的重点研究对象，每辆车都有自身唯一的车牌号码，车牌号码反映了车辆信息以及关联着车主信息，通过车牌号码可以记录对应车辆的交通行为，因此，车牌识别技术是智能交通系统中最核心最基础的技术之一，决定着智能交通系统的发展速度和技术水平。</p>
<p>　　车牌智能识别能够实时地对城市的车辆进行检测、监控和管理，实现智能交通的实时性和高效性；它不仅可以有效地减少人工操作的参与，节约成本；还可以在一定程度上杜绝一些交通工作人员的违规、舞弊操作，解决收费流失等问题；它还可以对城市的过往车流量进行检测、指导相关工作，减少交通拥堵现象。</p>
<p>　　在这个大力倡导智慧型城市概念的社会，随着互联网技术的提升，网络的发展，智能的车牌识别系统早已经深入人们的生活中，监测车流量等。</p>
<p>　　<strong>电子警察系统</strong>：一种抓拍车辆违章违规行为的智能系统，大大降低了交通管理压力。</p>
<p>　　<strong>卡口系统</strong>：对监控路段的机动车辆进行全天候的图像抓拍，自动识别车牌号码，通过公安专网与卡口系统控制中心的黑名单数据库进行比对，当发现结果相符合时，系统自动向相关人员发出警报信号。</p>
<p>　　<strong>高速公路收费系统</strong>：自动化管理，当车辆在高速公路收费入口站时，系统进行车牌识别，保存车牌信息，当车辆在高速公路收费出口站时，系统再次进行车牌识别，与进入车辆的车牌信息进行比对，只有进站和出站的车牌一致方可让车辆通行。</p>
<p>　　<strong>停车场收费系统</strong>：随处可见，收费系统抓拍车辆图片进行车牌识别，保存车辆信息和进入时间,并语音播报空闲车位，当车辆离幵停车场时，收费系统自动识别出该车的车牌号码和保存车辆离幵的时间，并在数据库中查找该车的进入时间，计算出该车的停车费周，车主交完费用后，收费系统自动放行。</p>
<p>　　<strong>智能公交报站</strong>：当公交车进入和离开公交站台时，报站系统对其进行车牌识别，然后与数据库中的车牌进行比对，语音报读车牌结果和公交线路。</p>
<p>　　车牌识别技术应用广泛，当然，上面所指的应用只是其中的一小部分。随着智能交通的迅猛发展，社会对车牌自动识别的需求量会越来越高多，技术上也会越来越高。</p>
<p>　　车牌自动识别系统也叫做LPR（License Plate Recognition）系统，目前国内做的比较成熟的产品有北京汉王科技有限公司开发的“汉王眼”车牌识别系统，厦门宸天电子科技有限公司研发的 Supplate系列，深圳吉通电子有限公司研发的“车牌通”车牌识别产品、亚洲视觉科技有限公司研发的 VECON-VIS 自动识别系统等。也有很多高校在研究这个课题。国外相对的在这个方面开始的比较早，同时他们的车牌种类单一，字符简单，容易定位识别有关，取得不错的成就。</p>
<p>　　关于车牌识别的研究，虽然国内外学者已经作了大量的工作，但仍然存在一些问题。在车辆还比较新的时候，车牌上的字迹清晰，较容易识别，随着车龄越来越大，车子经过风吹雨淋，车牌难免受到一定程度的磨损，这样就会造成识别的难度。比如车牌图像的倾斜、车牌自身的磨损、光线的干扰都会影响到定位的精度。</p>
<p>　　车牌字符识别是在车牌准确定位的基础上，对车牌上的汉字、字母、数字进行有效确认的过程。目前已有的方法很多，但其效果与实际的要求相差很远，难以适应现代化交通系统高速度、快节奏的要求。因而对字符识别的进一步研究也同样具有紧迫性和必要性。</p>
<p>　　<strong>我们实验室的所做的工作就是基于Linux实现一个具有可视化界面的车牌识别系统。重点在于针对特点的环境改善现有的车牌定位、检测和识别的算法，对其进行优化，实现车牌识别的准确率和精确度。</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　在年尾用了几天的时间将2014年的所有工作都总结了一遍，将之前的文档综合了下。</p>
<p>　　以下是LPR系统，车牌识别的一些总结资料。</p>
<p>第一篇：LPR研究背景</p>
<p>　　汽车的出现改变了以往出行徒步和以马代步的时代，极大地改变了人们的生活方式]]>
    </summary>
    
      <category term="LPR" scheme="http://silencewt.github.io/tags/LPR/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/tags/lab/"/>
    
      <category term="lab" scheme="http://silencewt.github.io/categories/lab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2014年年度总结]]></title>
    <link href="http://silencewt.github.io/2014/12/28/2014%E5%B9%B4%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    <id>http://silencewt.github.io/2014/12/28/2014年年度总结/</id>
    <published>2014-12-28T02:26:08.000Z</published>
    <updated>2014-12-28T02:29:08.000Z</updated>
    <content type="html"><![CDATA[<p>　　好好回顾了下，这一年自己走过的时光，发现很多事情真的不是自己可以计划和安排的，犹记去年的这个时候是怎样的告诉自己不能浪费时光，要好好对待自己，也给自己设定了目标，也有一部分达成了，一部分终归是不了了之了。到了年底，没想到这一年的时间就这样了没了，回顾过去，<strong>只为更好的前进，成为更好的自己</strong>。</p>
<p>　　2014年收获了很多，也失去了很多，感概最多就是没有好好的使用时间，但是，每次回过头来看，都会觉得这一段路走的很有必要，没有经历过这些，怎么会知道自己要的是什么，怎么会感受到自己的成长，也许，这就是人们常说的，成长的所失与所得。虽然这段日子没有什么惊天动地的大事件，但是确确实实给了我很多的东西，不仅仅是学习也是做人。2014基本可以分为几个阶段性报告。</p>
<h3 id="学习">学习</h3>
<p>1、1-4月属于真真正正的迷茫期。一月忙于各种研究生结业考试，天天呆在图书馆，除了考试不知道自己还能那忙什么，去实验室的时间就是休息娱乐。当然，这段时间也过得很充实，达到了我要的目标，成绩优秀，这样的日子在10月份的时候出了成绩，轻松拿得国奖，学生的最高奖项。</p>
<p>2、寒假回家，除了和家人愉快的玩耍之外，也静下心来想了想之后的生涯该怎么过，没有结果但是紧迫感越来越大，提早来了实验室。从放假回来到三月，一直在思考，该怎么度过剩下的时间，该怎么才能提升自我竞争力？我可以做什么？我想做什么？未来的职业是什么？这几个问题一直就这样困扰着我。导师方向的更改造成我很大的压力，这不是我喜欢的。实验室的压力和责任也很大，不能任性的扔下实验室的事情不管，但有不能放弃找工作的目的。就是这么纠结的过了一两个月。白天，看论文，学图像处理，看opencv，学机器学习，了解这方面的各种信息和资料；晚上，接触前端，接触互联网，学写网站。虽然会被各种杂事打断但基本就是这个节奏。</p>
<p>3、这两个月内，纠结归纠结，期间自己设定的目标还是有完成一点的。这段时间，让我真正的踏入<strong>图像处理和机器学习</strong>的大门，自学了图像检测，目标识别这个领域的知识。回过头来看，原来这些都很简单，量的积累确实换来了质的飞跃。我所谓的简单，只是局限于现有简单算法的实现和理解。优化以及实际应用这又是一个大的世界。</p>
<p>4、还踏入了互联网领域，通过各种渠道的信息，通过师姐，通过不断的关注最新互联网信息，开启联通外面世界之路。对于<strong>构建网站，博客，页面交互，前端</strong>等等有了认识，接触了html，css，js，nodejs，mongodb，bootstrap，github，trello各种有趣的东西。学习这些的过程中，让我知道如何作用好网络找到自己想要的东西，如何查看官方文档，如何解决问题，不敢说每个都学的很深，不敢说都精通，但基本的我都知道。个人觉得重要的不是你学会了哪门技术，重要的是<strong>学会了怎么解决和处理问题，怎么寻求帮助，怎么思考，这个过程带给我的体会及自我进化才是慢珍贵的。</strong></p>
<p>5、在经过一段时间的挣扎，在听过阿里测试大讲坛之后，我坚定了要做测试这个行业的心，于是从5月开始就利用课余的时间重新将测试的东西捡起来，慢慢的深入到测试的领域，收集信息，找到自己想做的方向，web测试，由于自己对互联网很有的热情，鉴于之前接触了前端的知识，这一块能很快的上手，理解很快。这个期间，有尝试着去找实习，但是每次都被实验室的事情压着，没有办法顺利的离开，最后只能放弃。学习python，跟本科同学，尝试django建立一个网站，类似于博客收集信息的，界面基本上是copy某个网站的，只是内容和逻辑是自己的。</p>
<p>6、暑假回来后，对微信订阅号知道了怎么有效的利用了，重点关注了几个有效的订阅号，每天通过其了解最新的消息。坚持了2-3个月后，发现自己了解到的领域多了，知识面广了，和他人聊天的时候，什么话题都能聊下去，周围的人都说，我怎么知道这么多的。<strong>寻找消息的渠道，增长见识。</strong></p>
<p>7、下学期开学，变得更有目标性了，基本上就是图像处理（重点关注机器学习）和软件测试。开始完成车牌识别的项目，对于车牌识别领域的各个知识点都有所掌握，重点在字符识别这一块，结合<strong>python和机器学习</strong>这本书，完成了python的学习，加深对学习算法的理解。</p>
<p>8、之后，开始加入一个<strong>实验室的团队，做安卓开发</strong>，一个创业项目，手机App应用。由于本科有java和安卓的一点基础,花了7天的时间，通过极客学院的视频学习Android。这样时间被分为两段，白天在实验室，晚上在工作室那边。11月底，一方面感觉时间过于紧张，没有时间做自己的事情。实验室也有了新的项目，另一方面由于团队的内部原因，选择离开。</p>
<p>9、11月下旬开始接触自动化测试、单元测试、测试驱动开发思想、接口测试以及java、设计模式等等。</p>
<p>10、11月份开始，重点放在实验室项目上，<strong>三光检测系统</strong>，红外和可见光图像配准，图像融合，结合硬件在<strong>Linux</strong>下搭建便于三光检测的手持设备，该项目使用qt编程，有摄像头、视频服务器、pc主板、触摸屏等硬件设备，了解了融合硬件设备和软件的开发流程，自学了linux，由于是实际应用，对方只要知道是否可以在Linux下使用设备即可，所以只接触了简单的liunx，重点负责，Linux和图像融合配准模块。</p>
<h3 id="生活">生活</h3>
<p>11、上半年，组织实验室外出游玩三天，整个过程，从行程安排到住宿，坐车，吃饭，到游玩路线都是我一个人安排下来，全程自助游，路上不断收到大家的赞美声，都说安排的很好很贴心，太开心了。下半年，实验室周末的各种小聚，小活动，都组织得挺好的，为自己的<strong>交际能力和组织能力</strong>喝彩，总的一个感觉就是不管在实验室，在寝室，还是以前本科班，我的人缘还是很不错的，大家都愿意和我交流。这点希望继续保持，用一颗包容的心去对待大家，做一个大家眼里的开心果，传播正能量。</p>
<p>12、暑假回去帮哥哥忙活了大半个月，也算是尽到做妹妹的心了，照顾锦娴，帮助管理店里的生意，感触最深的就是：生活的不容易，各行各业都不是那么轻松的，自己做老板也不轻松，站在不同的位置就会有不同的角度看待问题，也就会有不同的烦恼问题出现。老板有老板的出发点，打工有打工的想法。其实都是不容易，唯有尽心尽力做好就好。不亏待自己，善待他人，包容理解换位思考。家里因为多了个小孩，变得更好欢乐了，只能说小孩好萌，好可爱啊~~~，和小孩接触就了，才发现自己也有一颗童心，未泯的赤子之心。</p>
<p>13、和闺蜜相处融洽，大家都说我们谁也离不开谁。我们能从09年一直走到现在，5年的友情，除了彼此的包容之外，更多的是彼此的维护，愿意为对方迁就自己的一些东西，<strong>愿意用心经营，愿意倾听</strong>。我一直相信，任何一段感情，不管是亲情、友情还是爱情都是需要彼此用心经营的，双方都需要付出，需要包容，若有一方从不付出，再浓感情慢慢的也会随着时间消失。对待生活的态度上，我觉得自个比较像“鬼脚七”（一个很有名的自媒体人），他对网友的一些回答我都很赞同，在价值观上挺一致的。</p>
<p>14、在瑜伽馆兼职了一段时间，爱上了瑜伽，深深感受到瑜伽的魅力，瑜伽成为我的业余爱好，以后有机会要好好的学学瑜伽。</p>
<h3 id="感情">感情</h3>
<p>15、顺其自然，能遇到一个懂你的人不容易，但还是希望那个他能快点出现，不要让我等久了。</p>
<p>　　这一年，给自己一个赞，也希望自己改掉拖拉的毛病，在年尾将所有的工作做个总结和了断，该写报告的写报告，该做记录的做记录，博客该发的发，来年不再为2014年买单了。所有的这些就在元旦前结束。</p>
<p>　　来年，愿自个不再拖延，坚持写博客，每周一次整理和总结所学的知识点，找个好的实习、好的工作，羽毛球技术飞升，和闺蜜好好的享受生活，好好的维持实验室的欢乐氛围，总之：<strong>用心生活，享受乐趣，不让自己遗憾。</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　好好回顾了下，这一年自己走过的时光，发现很多事情真的不是自己可以计划和安排的，犹记去年的这个时候是怎样的告诉自己不能浪费时光，要好好对待自己，也给自己设定了目标，也有一部分达成了，一部分终归是不了了之了。到了年底，没想到这一年的时间就这样了没了，回顾过去，<strong]]>
    </summary>
    
      <category term="总结" scheme="http://silencewt.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="心路历程" scheme="http://silencewt.github.io/tags/%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/"/>
    
      <category term="心路历程" scheme="http://silencewt.github.io/categories/%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[测试之美有感]]></title>
    <link href="http://silencewt.github.io/2014/12/28/%E6%B5%8B%E8%AF%95%E4%B9%8B%E7%BE%8E%E6%9C%89%E6%84%9F/"/>
    <id>http://silencewt.github.io/2014/12/28/测试之美有感/</id>
    <published>2014-12-28T02:18:07.000Z</published>
    <updated>2014-12-24T12:55:54.000Z</updated>
    <content type="html"><![CDATA[<p>　　<strong>王小波说：这个世界上有两种人，一类人将有趣的事情做成无趣，一类人把无趣的事情做成有趣。</strong>软件测试原本是件很有趣的事情，可是网上有很多的人或者一些做测试的人很不幸将测试这件有趣的事做成了无趣的事情：觉得是日复一日的手工劳动，不断的和开发人员争执，等等……但其实不是这样的。测试是一个软件项目，公司成功的基石，是一种在成本、质量、效率、周期之间平衡的艺术。</p>
<h3 id="一、性能测试，协作是关键">一、性能测试，协作是关键</h3>
<p>　　性能测试是比较复杂的一个测试环节，比如对一个学生进度跟踪系统，客户会要求“100%的网页在5秒或者是更短的时间内显示出来，应用程序支持1000及以上用户同时使用，98%的情况下，课程将在第一次尝试时就完全正确下载”，等等。虽然这是客户的要求，在这样是不可以写进目标里的，因为这完全无法验证，不能讲模棱两可的性能指标写到合同义务中。性能测试应该做到可度量有价值。将其改为“对于内部版本（出现情况需上报），在任意数量的用户条件下，有超过5%的情况加载网页的时间超过5S，超过2%的情况，课程无法完整或正确的下载……对于外部版附有性能报告，包括在，任意数量的用户条件下，有超过5%的情况加载时间超过5S的网页，超过2%的情况无法完整或正确下载的课程……”。<br>　　<strong>对于性能测试的需求从承诺达到一定水平转变为承诺报告在什么样的条件下目标将无法实现。这个过程就涉及到项目经理，客户，开发人员之间的交流和协作。</strong><br>　　但是面对这样的目标还是无法给出测试用例，那么应该在系统中设置检查点，策略：收集系统性能指标基准，并验证使用模型中包括的每个功能任务，分别在1个用户的负荷下，10个用户，1000甚至更多负荷下载每一个包含该功能任务的性能测试中都达到性能需求，每一个下面都需要列出功能任务清单。一个系统的性能是客户最关注的，但是你无法不能性能测试所有的东西。文中用一个超级杯营销的案例，说明性能测试需要与其他测试人员协作，于项目管理协作，于客户协作，于开发团队协作，于IT人员协作，以及与最终用户协作。</p>
<h3 id="二、模糊测试，让系统更可靠">二、模糊测试，让系统更可靠</h3>
<p>　　模糊测试大多数用于办公软件，<strong>那什么是模糊测试：是通过对输入数据进行随机修改和破坏来测试程序的方法。</strong>他为测试和编程人员在开发软件时面临的棘手问题提供多种优美的解决方案。办公软件需要支持很多种格式，我们或许能找到特定格式的文档，但这些文档可能不准确或有丢失处。例如与其他软件之间的互操作性，我们就需要模拟其他复杂软件，或者用一个模糊器生成范围很广的各种文档来模拟各种应用软件和软件版本的差别。office2007在开发的时候就大量使用了模糊测试。<br>　　在进行模糊测试的时候需要准备一组有代表性的文档，一个模糊器，从常规模型到自定义模型。在测试过程中也要不断的修改你的模糊器，以产生更多的测试用例并去除可能影响输出的偏差。模糊测试擅长发现诸如崩溃和挂起的明显问题，但对判断正确性的作用很小。在办公软件领域，它对开发和测试人员所面临的操作性、安全性、和稳定性在内的许多复杂问题提供有创意且简洁的解决方案。</p>
<h3 id="三、自动化测试">三、自动化测试</h3>
<p>　　自动化测试不仅仅是简单的编写和运行那些不需要人为干预的测试用例。事实上，在很多测试人员看来，自动化这是由一些手动生成的，用来执行特定测试场景或一部分产品功能的测试脚本或代码组成。但是很多时候自动化测试并没有给测试人员带来方便，因为除了实际的执行程序之外，流程中的其他部分没有一个实现了自动化。那么为了实施自动化，特别是规模较大的自动化测试，整个过程从头到尾—从测试人员编写玩测试程序到结果被分析出来给人看，都必须自动化。如果没有这个层次上的自动化，测试人员在监控测试程序运行上所花的时间将会变成难以控制的增长。<br>　　在什么情况下自动化可以帮助测试团队，以及什么情况下自动化会妨碍测试的工作，应该百分百的自动化那些应该被自动化的测试，这一准则本身是简单多额，困难就在于决定那些是应该被自动化的，产品架构，相关参与者，都可以帮助测试团队做出正确的决定。很多自动化之所以失败的原因在在于测试人员花太多的时间进行自动化或者试着去自动化，并把时间花在了根本不值得自动化的目标任务上。<br>　　一个基本的自动化测试流程：编写自动化测试—-选择测试和测试平台—-运行测试—-收集用于报告的测试结果—-报告新的额bug解决已近修复的bug。自动化测试要成功的第一步是：测试代码要写得棒。必须要能够易于维护，要对测试带进行源代码控制，并且集中编译和创建。测试员可以成为设计和实现系统测试框架的专家，这于应用程序开发是不一样的。<strong>编写一个漂亮的测试自动化工具需要对被测系统的理解，需要对可能将要编写的测试的理解，需要知道哪些测试对项目最优价值，还需要知道哪些测试最可能在将来随着被测软件的变化而具有可维护性。</strong><br>　　<em>如果在某一阶段，测试通过率仅为94%，你会怎么做？对于合理的测试通过率目标，与其去设定一个神奇的数字，你真正需要的是100%的失败调研并确保那些失败中没有一个严重到阻碍发布。回答”这要看失败来定了，如果阻碍我么达到目标的错误不满足我们的门槛，我们就让他过去“</em></p>
<h3 id="四、测试随机数发生器">四、测试随机数发生器</h3>
<h3 id="五、QA不是魔鬼">五、QA不是魔鬼</h3>
<p>　　测试人员是好的流程的促进者，能准确的发现（在发布之前）软件需求与实现之间不吻合的人，也是最广泛了解软件开发实践的人，对项目总体状态最了解的人。QA的工作是引导软件开发过程以提高成功率，以及建设性的批判软件开发过程而不是阻碍这个过程并成为拖后腿的人。<br>　　检验：通过重复的操作来确认事情做得正确的过程。<br>　　调查：反馈驱动的过程<br>　　很多人认为测试就是简单的触屏和点击，无聊的文本进行，是一个简单无聊的工作，如果这么想就错了，这样的工作不是调查而是检验。测试不仅仅是这些，测试往往需要和各类人员沟通，测试是对产品质量负责，保证每个产品能满足客户的需求及时上线。</p>
<h3 id="六、高效测试">六、高效测试</h3>
<p>　　软件测试中首要考虑的问题就是：安全性测试。导致用户数据的丢失是一件很糟糕的事情！安全性测试必须最早考虑，因为其贯穿在整个产品的架构之中。即架构上如果有所改动，那么几乎需要重新测试所有的东西，比如如果数据库的权限有问题，那么就不得不重新测试所有与数据库交互有关的测试用例，或者一旦程序和操作系统的交互存在安全问题，所有与操作系统交互有关的测试用例也必须重测。安全性对于应用程序的测试几乎会影响到每一个测试领域，需涉及到整个应用程序，对于安全性要求高的领域最好有相关的信息安全人员提供高级全面的解决方案。<br>　　在互联网应用程序中，可以考虑一下几个问题：跨站脚本、SQL注入、越权访问、信息泄露。</p>
<h3 id="七、查找缺陷">七、查找缺陷</h3>
<p>　　问：如果处于整个软件开发周期的最后一个环节：所有的新功能都实现了所有的测试用例也通过了，那么产品可以发布了吗？<br>　　理论上讲是测试用例都通过了就没有问题了，但是怎么保证你的测试集是完美的，如何才能知道你的测试集能有效的检查出缺陷。在这种情况下，可以系统化的植入认为的缺陷，然后测试集能否发现他们。测试集的代码覆盖率就是量化的度量测试集的质量指标（检查是否执行了程序的每一种状态）、分支覆盖率（保证代码中的分支至少被执行一次）、条件覆盖率（保证代码中每个条件分支子条件都经历过是和否的状态）。80%的缺陷都集中在20%的模块中。<br>　　覆盖率只能告诉你测试执行的情况并没有测试集本身的信息。可以使用变异测试，在程序中植入大量的人为的漏洞，并逐个对他们进行测试看哪些变异没有检测出来。然后系统化的改进这个测试集，知道所有的变异都能被检测出来。但是变异测试非常耗时。变异测试依赖于自动化测试。<br>　　问：怎么对程序进行变异呢？改变常量的值（对某一常量X，尝试用X-1,X+1，0来替换），用常量来替换变量的值，用变量来替换数组的引用，改变操作符，改变调用方法，将某一条件置返（判断条件c为非c）。改变数字操作符+改成-,&gt;&gt;改成&lt;&lt;。省略方法调用(将一个方法调用直接改为0.如果该方法不需要返回值，可以直接删除)。</p>
<h3 id="八、测试分类">八、测试分类</h3>
<p>　　黑盒和白盒测试是软件测试中最普遍的设计方法，在黑盒测试中，软件被看做是一个神秘的对象，他的内部结构和设计是未知的，他接受一些输入数据，对数据进行处理，然后输出结果。如果一个程序能正确处理数据并输出预期的结果，则认为测试师成功的。黑盒测试是以软件说明书为基础的，而白盒测试则需要具有软件内部实现的了解，并关注于程序的某一特定路径的测试。程序员要小心的选择测试用例以覆盖所有重要的代码单元。虽然黑盒和白盒测试方法是互相补充的，但二者都有一些共同的局限。其中主要的一个问题就是他们都不能对程序进行全面的测试。这就要求你富有创造型、有效的进行设计，甚至为了在用户使用软件之前将缺陷找到，还要开发出漂亮的测试来覆盖个整蛊你用例。<br>　　静态分析：白盒测试一种，不需要代码的执行，在于查找一般性错误确保代码满足所有重要的要求和标准。一般自动化执行。例如GCC编译器是静态分析工具。<br>　　单元测试：白盒测试一种，检查代码单元个体单个函数或模块是否正常工作，是否接受和处理数据u，并返回预期的值。<br>　　测试脚本：一系列逐步运行的指令集合，再现各种不同的条件来检查程序各项功能是否正常，模仿日常对应用程序的使用，给定在一系列牌值下下能否输出正确的的结果。不关心程序的内部细节。 </p>
<hr>
<p>　　<br>　　<em>这本书并不适合出学者看，建议有了一定的测试基础之后在过来看本书。以上的只是书里的一些摘录，对于测试的理解还不是很深入，但是对于测试会有一点大概的了解，书中提到的一些经验还是不错的，但是个人感觉这本书有点旧时了，不建议看。当然这个只能我个人的看法。</em></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　<strong>王小波说：这个世界上有两种人，一类人将有趣的事情做成无趣，一类人把无趣的事情做成有趣。</strong>软件测试原本是件很有趣的事情，可是网上有很多的人或者一些做测试的人很不幸将测试这件有趣的事做成了无趣的事情：觉得是日复一日的手工劳动，不断的和开发人员]]>
    </summary>
    
      <category term="测试" scheme="http://silencewt.github.io/tags/%E6%B5%8B%E8%AF%95/"/>
    
      <category term="读书笔记" scheme="http://silencewt.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="笔记" scheme="http://silencewt.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[opencv函数系列---漫水填充floodfill]]></title>
    <link href="http://silencewt.github.io/2014/12/28/opencv%E5%87%BD%E6%95%B0%E7%B3%BB%E5%88%97-fillfood/"/>
    <id>http://silencewt.github.io/2014/12/28/opencv函数系列-fillfood/</id>
    <published>2014-12-28T02:18:07.000Z</published>
    <updated>2014-09-16T13:57:22.000Z</updated>
    <content type="html"><![CDATA[<h3 id="一、floodFill思想">一、floodFill思想</h3>
<p>　　所谓漫水填充，简单来说，就是自动选中了和种子点相连的区域，接着将该区域替换成指定的颜色，这是个非常有用的功能,经常用来标记或者分离图像的一部分进行处理或分析.漫水填充也可以用来从输入图像获取掩码区域,掩码会加速处理过程,或者只处理掩码指定的像素点。操作结果总是某个连续的区域。当邻近像素点位于给定的范围（从lodiff到updiff）内或在原始seedPoint像素值范围内是，floodFill将会为这个点涂上颜色。以此填充算法为基础，类似photoshop的魔术棒选择工具就很容易实现了。<br>　　漫水填充（FloodFill）是查找和种子点联通的颜色相同的点，魔术棒选择工具则是查找和种子点联通的颜色相近的点，将和初始种子像素颜色相近的点压进栈作为新种子。<br>　　泛红填充实现最常见有四邻域像素填充法，八邻域像素填充法，基于扫描线的像素填充方法。根据实现又可以分为递归与非递归（基于栈）。</p>
<h3 id="二、函数介绍">二、函数介绍</h3>
<p>　　</p>
<pre><code>floodFill ( InputOutputArray image,   <span class="comment">//输入/输出1通道或3通道，8位或浮点图像，具体参数由之后的参数具体指明InputOutputArray mask,     </span>
     Point seedPoint,                <span class="comment">//漫水填充算法的起始点</span>
     Scalar newVal,                   <span class="comment">//像素点被染色的值，即在重绘区域像素的新值</span>
     Scalar loDiff=Scalar(), 
     Scalar upDiff=Scalar(), 
     CvConnectedComp*  comp = <span class="keyword">NULL</span>
     <span class="keyword">int</span> flags=<span class="number">4</span> )
</code></pre><p>　　mask：表示操作掩模,（控制被填充的区域）。它应该为单通道、8位、长和宽上都比输入图像 image 大2个像素点的图像（是内部运算简单快速）。floodFill需要使用以及更新掩膜。需要注意的是，漫水填充不会填充掩膜mask的非零像素区域。例如，一个边缘检测算子的输出可以用来作为掩膜，以防止填充到边缘。同样的，也可以在多次的函数调用中使用同一个掩膜，以保证填充的区域不会重叠。另外需要注意的是，掩膜mask会比需填充的图像大，所以mask中与输入图像(x,y)像素点相对应的点的坐标为(x+1,y+1)。<br>　　<br>　　lodiff、updiff：表示当前观察像素值与其部件邻域像素值或者待加入该部件的种子像素之间的亮度或颜色之负差（lower brightness/color difference）或正差的最大值。 如果一个像素点的值不低于被染色的相邻点减去lodiff且不高于其加上updiff，那么该像素点就会被染色。如果flags参数包含FLOODFILL_FIXED_RANGE 这时每个像素点都将于种子点而不是相邻点比较。可以理解成阈值范围，在这个范围里的像素都会被染色。<br>　　<br>　　flags：低8位（第0~7位）用于控制算法的连通性，可取4 (4为缺省值) 或者 8。如果设为4，表示填充算法只考虑当前像素水平方向和垂直方向的相邻点；如果设为 8，除上述相邻点外，还会包含对角线方向的相邻点。高8位部分（16~23位）可以为0 或者如下两种选项标识符的组合：<br>　　（1） FLOODFILL_FIXED_RANGE－如果设置为这个标识符的话，就会考虑当前像素与种子像素之间的差，否则就考虑当前像素与其相邻像素的差。也就是说，这个范围是浮动的。<br>　　（2）FLOODFILL_MASK_ONLY－如果设置为这个标识符的话，函数不会去填充改变原始图像 (也就是忽略第三个参数newVal),而是去填充掩模图像（mask）。中间8位部分，上面关于高八位FLOODFILL_MASK_ONLY标识符中已经说的很明显，需要输入符合要求的掩码。Floodfill的flags参数的中间八位的值就是用于指定填充掩码图像的值的。但如果flags中间八位的值为0，则掩码会用1来填充。<br>　　而所有flags可以用or操作符连接起来，即“|”。例如，如果想用8邻域填充，并填充固定像素值范围，填充掩码而不是填充源图像，以及设填充值为47，那么输入的参数是这样：</p>
<pre><code><span class="attribute">flags</span>=<span class="string">8 | FLOODFILL_MASK_ONLY | FLOODFILL_FIXED_RANGE | （47&lt;&lt;8）</span>
</code></pre><h3 id="三、函数演示">三、函数演示</h3>
<p>待写ing……</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="一、floodFill思想">一、floodFill思想</h3>
<p>　　所谓漫水填充，简单来说，就是自动选中了和种子点相连的区域，接着将该区域替换成指定的颜色，这是个非常有用的功能,经常用来标记或者分离图像的一部分进行处理或分析.漫水填充也可以用来从输入图像]]>
    </summary>
    
      <category term="opencv" scheme="http://silencewt.github.io/tags/opencv/"/>
    
      <category term="opencv" scheme="http://silencewt.github.io/categories/opencv/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[时间管理--小强升职记]]></title>
    <link href="http://silencewt.github.io/2014/12/28/%E5%B0%8F%E5%BC%BA%E5%8D%87%E8%81%8C%E8%AE%B0/"/>
    <id>http://silencewt.github.io/2014/12/28/小强升职记/</id>
    <published>2014-12-28T02:18:07.000Z</published>
    <updated>2014-09-16T13:47:36.000Z</updated>
    <content type="html"><![CDATA[<p>　　书中已对话的形式，主管老付如何教会小强对自己时间进行管理，如何高效的完成工作，培养其成为主管。<br>　　在我们觉得时间很多的时候，他就偷偷的溜走了，时间对于每个人都是公平的。我们每天在忙忙碌碌的日子里过去，是否过得有意义，浑浑噩噩的日子真的是我们所要的吗？到底我自己追求的是什么？每天工作学习是为了什么？什么样的人生才有意义?我们需要站在一个更高的位置上审视自己。问问自己什么才是真正想要的。<br>　　<br>　　我们的时间总是在无意义的事情上面一点点的浪费掉。确实如此，以前总是每次开电脑的时候。登下QQ，看下新闻什么的，以为这样浪费不了多少时间，可是每次都没有忍住，还有点像滚雪球似的的越滚越长，结果一看时间已经10:00多了，过一会就要吃饭了，自然就没有心思学习了，或者每次时间很轻易的就被同学打断，被QQ消息打断，那么在要集中注意就很难，就是这样的时间黑洞将我们的时间吞噬掉。<br>　　<br>　　有时候也会有同时有很多事情向我袭来，很多时候就应该根据自己的价值观，给他们分出优先级，找出核心事件，及时解决这些问题。时间管理的方法有很多，四象限法则，时间投资法，衣柜整理法等，具体哪一种是适合你的，还是需要自己去摸索，去实践才知道什么是适合自己的。书里的时间资本法，对于时间价值的计算让我忽然醒来，原来我的时间就剩这么一点了，可是我想要的生活还没有实现。。<br>　　<img src="/images/zbjs2.png" alt="资本计算2"><br>    <img src="/images/zbjs.png" alt="资本计算"><br>　　很典型的，在今后工作的日子里，只有8年是在工作，有10年是在睡觉，其他时间是13年，有人曾统计过一个人活得72岁时对时间的消费情况：睡觉21年，工作14奶奶，个人卫生7年，吃饭6年，旅行6年，排队5年，学习4年，开会3年，打电话2年，找东西1年，其他3年。如果加上我们的年新来计算时间资本，那么很廉价。。</p>
<h3 id="目标">目标</h3>
<p>　　时间，是一个非常奇怪的东西，当你想挥霍它的时候，它会尽量的满足你，让你觉得怎么挥霍都用不完。但是当你想要珍惜它的时候，他又会i特别的吝啬，让你觉得时光飞逝，转眼已是尽头。<br>　　对于一个项目或是什么要有明确的目标，具体的下一步行动，一个行动清单。对人生有规划，有明确的目标是很好的，但如果沉迷在未来美好生活的幻想中，而不是执行它，只是做个梦想家，我们要将目标化为行动，做个建筑家，梦想的缔造者。<br>　　当然，目标也不是有了完美的计划就能达成的，我们需要方法避免失败。<br>　　1、找到最大的石头，就是要问问自己实现这个目标最大的石头（障碍）在哪里，如果最大的石头没有移除，你除去了99%的小石头也是没有用的。<br>　　2、有什么想法计划一定要写下来，白字黑子是最好的契约，写到了才可以做到，那么所有的想想就不再只是想想了，而是需要实现的东西了。<br>　　3、拒绝第一次失败，万事开头难，很多目标的夭折都是从第一次失败开始的。所以我们要重视第一次的是吧，摆正心态不让它产生连锁反应。我们有一种很可怕的适应性，不敢是对好习惯还是坏习惯的适应。失败了，我们更应该找出原因，为什么会失败？到底为什么成功？花时间思考这两个问题是非常重要的。</p>
<h3 id="习惯">习惯</h3>
<p>　　习惯是个很可怕的东西，对于长期做在电脑前的上班族，最重要的一点就是要养成健身的习惯，平时我们可能没有大把的时间可以去运动，为了身体的健康，每天坚持一个小时的锻炼。向着你要养成多习惯，每天去做一些你不愿意的事情，这样你就不会为那些真正需要你完成的责任而痛苦。</p>
<h3 id="思维导图">思维导图</h3>
<p><img src="/images/swdt.bmp" alt="思维导图"></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　书中已对话的形式，主管老付如何教会小强对自己时间进行管理，如何高效的完成工作，培养其成为主管。<br>　　在我们觉得时间很多的时候，他就偷偷的溜走了，时间对于每个人都是公平的。我们每天在忙忙碌碌的日子里过去，是否过得有意义，浑浑噩噩的日子真的是我们所要的吗？到底我自己追]]>
    </summary>
    
      <category term="读书笔记" scheme="http://silencewt.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="笔记" scheme="http://silencewt.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
